{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" width=\"12%\" style=\"padding-right:10px;\" src=\"../Images/Ccom.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrated Seabed Mapping Systems <a href=\"https://piazza.com/class/jzvaaav18cf2j7\"><img src=\"../Images/help.png\"  title=\"Ask questions on Piazza.com\" align=\"right\" width=\"10%\" alt=\"Piazza.com\\\"></a><br><br> Lab B: Refraction (Fall 2019)\n",
    "\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"../Images/refraction1.png\"><br><br>\n",
    "\n",
    "## Lab intent\n",
    "\n",
    "\n",
    "This second lab is designed to encourage you to implement your own ray tracing algorithm for class `SSP`. This should be developed as a method for use in the last lab of the term (when you will have to ray trace 400-800 beams from a single swath cycle).\n",
    "\n",
    "That function will have as input:\n",
    "\n",
    "    1.A starting depression angle\n",
    "    2.A starting depth\n",
    "    3.A two-way travel time\n",
    "\n",
    "And from that you will calculate two things :\n",
    "\n",
    "    1.depth of the bottom strike\n",
    "    2.Radial distance out from transducer to the bottom strike\n",
    "    \n",
    "To help you understand the significance of sound speed variability, this lab will allow you to calculate:\n",
    "\n",
    "    •how long it should take for sound to reach a flat seafloor of a given depth\n",
    "    •How much of a depth (and radial distance error) would result if you use the wrong sound speed profile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"../Images/mvp.png\"><br><br>\n",
    "\n",
    "The profiles you will be using as examples are real measurements taken using a **Moving Vessel Profiler” (MVP)**. The model used was an ODIM MVP-300 (The system is now built and marketed by AML). This is designed to be used to take underway profiles to a depth of up to ~300m from a vessel moving at 12 knots. The example is from a MVP-300 installed on the Canadian Coast Guard Ship (CCGS) Amundsen, Canada’s research icebreaker.\n",
    "\n",
    "The MVP-300 towfishis equipped with a Seabird CTD 911+ sensor measuring **Conductivity** (proxy to salinity), **Temperature**, and pressure (proxy to **Depth**), known as a **CTD**. From those measurements, the speed of sound is modeled for use by the ship-mounted EM300 30 kHz multibeam sonar.\n",
    "\n",
    "The towfish is dragged continuously behind the vessel at a depth just above the multibeam transducer. When released to freefall, it falls at a speed of about 5m/s and thus it takes about one minute to drop from near the surface to 300m. The limiting time however is that taken to winch back in the sensor. In that time, the vessel has moved forward 60x6m/s = 360m. Thus there is a total of ~ 700-800m of cable deployed. The recovery speed is about 1m/s so it takes about 10 minutes to get all the cable back in.\n",
    "\n",
    "It can thus deploy every ~15 minutes in if need be. For the example shown here it was set to cycle every 30 minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"../Images/ssp_area.png\"><br><br>\n",
    "\n",
    "The example used in this lab here is a transect of 18 profiles taken at ½ hour intervals along a NE-SW transect across the Labrador Current. The section took 9 hours to acquire covering a total transit of ~110 nautical miles.\n",
    "\n",
    "The section covers from the main open Labrador Sea, onto the continental shelf where the Labrador Current is flowing from North to South, bringing cold brackish water from Baffin Bay down onto the Grand Banks.\n",
    "\n",
    "The area is of high survey significance to Canada when considering drilling on the Labrador Margin. The largest single impediment to drilling is the presence of huge icebergs that are swept down from Greenland in the Labrador Current. These icebergs carve giant grooves on the continental shelf and are thus an active hazard for oilfield infrastructure.\n",
    "\n",
    "Your challenge is to accurately survey the outer shelf (200-300m depth) with sufficient accuracy (let's say IHO Order 1 so ~+/-1% of depth). To achieve this accuracy you must have a reasonable approximation of the sound speed structure.\n",
    "\n",
    "This data set illustrates typical changes in that structure over a distance of ~6 nautical miles (1/2 and hour of ship time). Most ships **do not** have an MVP and thus sound speed profiles are usually only taken at intervals of 3-6 hours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Temperature and Salinity Structure along the section\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"../Images/t_s_map.png\"><br><br>\n",
    "The figure above shows you the temperature and salinity structure along the section.\n",
    "\n",
    "Note the coldest and most brackish water in the south flowing Labrador current. That water is most brackish and slightly warmer at the surface. Cold and salty is more dense of course. Note however, that on the outer shelf there is a mid-water (~50-100m depth) temperature maximum with colder water above. If there were no other variation, this would be unstable as colder water should be heavier. But looking at the salinity we see that the surface waters are more brackish and thus make the water less dense even though it is colder.\n",
    "\n",
    "Indicated in the figure above are the locations of profiles 112 and 113 from which you have to do the calculations. Additionally, profiles 102 and 103 are also indicated. You will be asked what you think the influence of the change is there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Derived Density and Sound Speed Structure\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"../Images/rho_ss_map.png\"><br><br>\n",
    "The plots above  are derived from the salinity and temperature structure shown in the previous section.\n",
    "\n",
    "The top plot is density and is derived using the **UNESCO equations**, knowing temperature, salinity and pressure. As can be seen the density structure most strongly mimics the salinity structure, indicating that the salinity is the more significant factor in density in this case.\n",
    "\n",
    "The lower plot is the sound speed which is derived using the Chen and Millero publication (again knowing temperature, salinity and pressure). In this case, the structure most closely resembles the temperature structure seen on the previous page. Thus clearly temperature is a greater influence on sound speed in this environment than salinity.\n",
    "\n",
    "As previously the locations of profiles 112 and 113, from which you have to do the calculations, are shown; profiles 102 and 103, where you are going to be asked what you think the influence of the change is, are also shown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### How much the Water Mass can change in ~½ an hour\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"../Images/ssps_over_time.png\"><br><br>\n",
    "\n",
    "The figure above illustrates two sequential MVP dips. In real time, you only have the last dip available to calculate the refracted ray path. Thus for the ~½ hour after the first dip has been acquired, all calculations are being performed using a water mass that is become increasingly out-of-date.\n",
    "\n",
    "After 40 minutes, a second dip takes place. You can see that the water-mass is remarkably different. Even though the near-surface sound speeds and the ones at ~250m depth are almost identical, for the majority of the profile, the newer dip reveals much slower sound speeds.\n",
    "\n",
    "Note that, while the near surface sound speeds are almost identical, the reason for them being this value is quite different. In the first cast it was due to cold-salty water. Now, almost the same sound speed value is being reported, but for warmer less salty water.\n",
    "\n",
    "How much does all this matter? In this lab, you will quantify the exact depth and radial distance error that results in from rays traced assuming the old water-mass, when if fact, the underlying water is the new water-mass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Estimating the Refraction Error\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"../Images/refraction_error.png\"><br><br>\n",
    "\n",
    "To estimate the resulting error, you need to compare actual depth with the resultant erroneous depth. That error will vary both with total depth and incidence angle. As a result you need to pick a depth of interest (representative of the depth in which you are working). In this case we are picking a flat seabed at 250m depth. At that depth we then look at beams with incidence angles ranging from 0 (vertical incidence) to ~70 degrees (the widest you would be likely to attempt bottom detection).\n",
    "\n",
    "##### Calculating the true TWTT and the true Radial distance\n",
    "\n",
    "We need to find out the true TWTT and resulting radial distance that would result from beams over that range of incidence angles. To do that, one merely performs a ray trace, but in this special case the depth is known, but the TWTT is unknown (the reverse of the usual situation). Thus, you are tracing, keeping track of the TWTT accumulated until you arrive at your desired depth. As a result of this you will calculate an array of TWTTs and radial distances for the range of incidence angles you are testing for (for example 0 to 70 degrees at 1 degree intervals). You do this for the actual water-mass that you are really in.\n",
    "\n",
    "##### Calculating the Erroneous Depth and Radial Distance\n",
    "Now that you have this set of TWTTs , you use the usual forward calculation, tracing a ray through all the layers of the false sound speed profile until the TWTT is reached. You then compare the depth and across track distance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### Lab Deliverables\n",
    "\n",
    "The deliverables for this lab are code that produces two plots with the X-axis being the true across track distance\n",
    "\n",
    "    1. With the vertical axis axis being the vertical error\n",
    "    2. With the vertical axis being the horizontal error\n",
    "    \n",
    "In addition you will be asked a number of essay questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy import cos,pi,sin,pi\n",
    "from pathlib import Path\n",
    "\n",
    "lab_a=Path('../Lab_A/') # Get the path to your Lab_A folder\n",
    "sys.path.append(str(lab_a.resolve())) # add the Lab_A folder to the list of paths \n",
    "\n",
    "from mycode.position import *\n",
    "from mycode.SSP import SSP\n",
    "from mycode.analyzess import AnalyzeSS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## B.0 Reading the Sound Speed Profiles\n",
    "\n",
    "\n",
    "You already created a class to handle Sound Speed Profile (**SSP**) data in Lab A. We will further develop this class for our use in this Lab B. For convenience, and more importantly, not to create more than necessary versions of the class we will continue to use the same class definition file. In order to do this we need to add to the path where Python searches at run-time. The line:\n",
    "\n",
    "    lab_a=Path('../Lab_A/')\n",
    "    \n",
    "creates a `Path` object named `lab_a`. Relative to the current working directory we go up one directory and then into directory `Lab_A` which is where the folder `mycode` holding the .py files you created in lab A are located.\n",
    "\n",
    "    sys.path.append(str(lab_a.resolve()))\n",
    "    \n",
    "in the code cell above then adds the full path to the system paths. This now makes the .py code files in the `mycode` folder available for use here, as seen in the code cell below\n",
    "\n",
    "In this step we will need to determine the arc-cosine of angles. Make sure that at the top of `SSP.py` the following line is present\n",
    "    \n",
    "     from numpy import pi, cos, sin, log, exp, arccos\n",
    "     \n",
    "We will also need some of the functionality provided by the Position class - to this end also add the line:\n",
    "\n",
    "    from mycode.position import *\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'mycode.SSP.SSP'>\n"
     ]
    }
   ],
   "source": [
    "test=SSP()\n",
    "print(type(test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"../Images/ssp_mvp_format.png\"><br><br>\n",
    "\n",
    "##### The data content of the provided Sound Speed Profiles\n",
    "\n",
    "In the figure above you see the contents of two data files. We will need to create an additional data parser which is able to interpret the data collected with the MVP 300 System. You will find that often similar data are presented in very different ways to you, if your classes are well designed parsing these different data formats becomes an issue of simply adding read methods.\n",
    "\n",
    "The figure shows you the detailed format of the data content of each MVP dip file.\n",
    "As can be seen, the sensor is integrated with the shipboard navigation so that the following data are recorded:\n",
    "\n",
    "    1.Launch Location\n",
    "    2.Time of launch\n",
    "    3.Speed of vessel at launch\n",
    "    4.Depth at launch location\n",
    "\n",
    "All these are derived from NMEA telegrams (which are automatically preserved in the file).\n",
    "\n",
    "\n",
    "____\n",
    "### B.0.1 Add Variables to the SSP class\n",
    "\n",
    "<img align=\"left\" width=\"6%\" style=\"padding-right:10px;\" src=\"../Images/test.png\">\n",
    "\n",
    "Update the SSP `__init__` by adding the fields `self.vessel_speed` and `self.bot_depth` and give them the value `None`\n",
    "<br><br><br>\n",
    "___\n",
    "### B.0.2 Parse the Header of MVP Data Files\n",
    "\n",
    "    def read_mvp_file(self, fullpath):\n",
    "\n",
    "        # Check the File's existence\n",
    "        if os.path.exists(fullpath):\n",
    "            self.metadata[\"Source File\"] = fullpath\n",
    "            print('Opening sound speed profile data file:' + fullpath)\n",
    "        else:  # Raise a meaningful error\n",
    "            raise RuntimeError('Unable to locate the input file' + fullpath)\n",
    "\n",
    "        # Open, read and close the file\n",
    "        svp_file = open(fullpath)\n",
    "        svp_content = svp_file.read()\n",
    "        svp_file.close\n",
    "\n",
    "        # Tokenize the contents\n",
    "        svp_lines = svp_content.splitlines()\n",
    "        \n",
    "        # Create a Position object       \n",
    "        pos = Position()\n",
    "        \n",
    "        n_lines = 0\n",
    "        for line in svp_lines:\n",
    "            print( line)\n",
    "            n_lines += 1\n",
    "        \n",
    "Add the method `read_mvp_file` shown above to the SSP class. If done correctly the code cell below will show you the contents of the MVP data file \"Oct4_slope.112m1.txt\" found in your \"Data\" directory for Lab B.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening sound speed profile data file:Data/Oct4_slope.112m1.txt\n"
     ]
    }
   ],
   "source": [
    "ssp=SSP()\n",
    "ssp.read_mvp_file('Data/Oct4_slope.112m1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B.0.2.0 Find the end of The Header\n",
    "\n",
    "What you will notice is that the meta data is separated from the various records. The other thing that you will notice is that the data contains the observations of the CTD (P, C, T) as well as data that are derived from these values (Dpth, SV, S, Rho). In our case we will read the data file in two parts, first the header and then the data records, and rather than processing the raw data (which would be a lab on its own) we will use the processed results.\n",
    "\n",
    "A simple way of reading just the header is to stop the execution of the for loop when the line 'P(dbar),C(mmho/cm),T(degC),Dpth(m),SV(m/s),S(PSS-78),Rho(kg/m^3)' is encountered. However, the problem with this is that for the MVP 30 the contents of the data records depend on the installed sensors, which means that the contents of this line may vary. However, the line describing the records is alway preceded by an empty line - we may use this to help us parse the file. \n",
    "\n",
    "Break the loop when the contents of `line` are equivalent to '', that is line is an empty string. If you now run the code cell above it should show you just the contents of the header, except for the last line: *P(dbar),C(mmho/cm),T(degC),Dpth(m),SV(m/s),S(PSS-78),Rho(kg/m^3)*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B.0.2.1 Find the Time\n",
    "\n",
    "You will see that there are more than one time contained in the file. The PC Time is problematic since it may be in any time zone and the clock may not be very accurate. The GNSS time contained in **NMEA-0183** records is much more accurate and always referenced to **UTC**. There is a dedicated time message known as a 'ZDA'. NMEA messages are always related to navigation. It does make sense to add a `function` to the `position.py` file that takes a ZDA NMEA messages and returns a datetime object. \n",
    "    \n",
    "In the `position.py` file add the following function at the end\n",
    "\n",
    "    def ParseNMEA0183_ZDA( dt_str):\n",
    "        obs = dt_str.split(',')\n",
    "        time = datetime( \n",
    "                int( obs[4]), int( obs[3]), int( obs[2]), \n",
    "                int( obs[1][0:2]), int( obs[1][2:4]), int( obs[1][4:6]),int(obs[1][7:])*10000)\n",
    "        return time\n",
    "\n",
    "Finally add an if statement that executes the following when `line[0:12]` == \"GPS Time\" in the `for` loop parsing the MVP file header in the `read_mvp_file()` method\n",
    "\n",
    "            # Parse the time\n",
    "            if line[0:8] == \"GPS Time\":\n",
    "                # Extract the ZDA record\n",
    "                obs = line.split()\n",
    "\n",
    "                # Extract the UTC time string\n",
    "                self.obs_time = ParseNMEA0183_ZDA(obs[2])\n",
    "                \n",
    "Make sure that you understand what the NMEA 0183 ZDA message contains by using an Internet search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B.0.2.2 Find the Position\n",
    "\n",
    "You will see that the vessel position is stored in another **NMEA-0183** record, namely a GGA record. GGA records are always referred to WGS84, Note that the MVP will store any type of positioning message. for now we will check to see whether we have a GGA message and create an error otherwise. \n",
    "\n",
    "In the `position.py` file add the following function at the end\n",
    "\n",
    "def ParseNMEA0183_GGA( dt_str):\n",
    "    \n",
    "    # Get the GGA string and tokenize it\n",
    "    gga_data = dt_str.split(',')\n",
    "\n",
    "    # verify that we have a GGA string\n",
    "    if not gga_data[0][-3:] == \"GGA\":\n",
    "        raise RuntimeError(\n",
    "                'ParseNMEA0183_GGA: argument `dt_str` must be a GGA message')\n",
    "\n",
    "                \n",
    "    # Determine the time of day from both the header and the GGA string\n",
    "     \n",
    "    gga_timedelta=timedelta(hours=int(gga_data[1][0:2]), \\\n",
    "                             minutes = int(gga_data[1][2:4]), \\\n",
    "                             seconds = int(gga_data[1][4:6]))\n",
    "           \n",
    "                \n",
    "    # Parse the latitude\n",
    "    if gga_data[3].lower() == \"n\":\n",
    "        lat = float(gga_data[2][0:2])+float(gga_data[2][2:])/60.\n",
    "    else:\n",
    "        lat = -float(gga_data[2][0:2])-float(gga_data[2][2:])/60.             \n",
    "\n",
    "    # Parse the longitude\n",
    "    if gga_data[5].lower == \"w\":\n",
    "        lon = float(gga_data[4][0:3])+float(gga_data[4][3:])/60.\n",
    "    else:\n",
    "        lon = -float(gga_data[4][0:3])-float(gga_data[4][3:])/60.               \n",
    "\n",
    "    # Parse the GNSS Quality indicator\n",
    "    q = int(gga_data[6])\n",
    "\n",
    "    # Parse the number of GNSS satellites used for the solution\n",
    "    n_sats = int(gga_data[7])\n",
    "\n",
    "    # Parse the HDOP Quality indicator\n",
    "    hdop = float(gga_data[8])\n",
    "\n",
    "    # Parse the orthometric height \n",
    "    height = float(gga_data[9])\n",
    "                \n",
    "    # Generate an error if the units of the orthometric height is not meters\n",
    "                                   \n",
    "    if gga_data[10].lower() != \"m\":\n",
    "        raise RuntimeError('Orthomeric height units are not meters!')                \n",
    "                \n",
    "    # Parse the geoid ellipsoid separation\n",
    "    separation = float(gga_data[9])\n",
    "                                   \n",
    "    if gga_data[12].lower() != \"m\":\n",
    "        raise RuntimeError('Orthomeric height units are not meters!') \n",
    "              \n",
    "       \n",
    "    # If there is more data then parse it\n",
    "    corr_age = None\n",
    "    corr_station = None\n",
    "    if not gga_data[13] == \"\":\n",
    "        corr_age = float(gga_data[13])\n",
    "        corr_station = float(gga_data[14][0:-3])\n",
    "                    \n",
    "    # For now, ignore the checksum (this would become a computer science assignment\n",
    "\n",
    "    return gga_timedelta, lat, lon, q, n_sats, hdop, height, separation, corr_age, corr_station\n",
    "\n",
    "Finally add an if statement that executes the following when `line[0:12]` == \"GPS Position\" in the `for` loop parsing the MVP file header in the `read_mvp_file()` method\n",
    "\n",
    "            # Parse the position\n",
    "            if line[0:12] == \"GPS Position\":\n",
    "                # Extract the ZDA record\n",
    "                obs = line.split()\n",
    "\n",
    "                # Extract the UTC time string\n",
    "                _, self.obs_latitude, self.obs_longitude, _, _, _, _, _, _, _ = ParseNMEA0183_GGA(obs[2])\n",
    "                \n",
    "Make sure that you understand what the NMEA 0183 ZDA message contains by using an Internet search.\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B.0.2.3 Find the Bottom Depth\n",
    "\n",
    "The next field that should be parsed is the bottom depth. Typically this is the instantaneous ocean depth, but there is no matadata that will allow us to verify this. Regardless we will interpret it as such\n",
    "\n",
    "\n",
    "Add an `if` statement that executes the following when `line[0:13]` == \"Bottom Depth:\" in the `for` loop parsing the MVP file header in the `read_mvp_file()` method\n",
    "\n",
    "            # Parse the Depth\n",
    "            if line[0:13] == \"Bottom Depth:\":\n",
    "                obs = line.split()\n",
    "                self.bot_depth=float(obs[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B.0.2.4 Find the Vessel Speed\n",
    "\n",
    "The last field that should be parsed is the vessel speed, the data file uses knots,but we want to use m/s so we need to divide the speed by 1.852\n",
    "\n",
    "\n",
    "Add an if statement that executes the following when `line[0:13]` == \"Bottom Depth:\" in the `for` loop parsing the MVP file header in the `read_mvp_file()` method\n",
    "\n",
    "            # Parse the Vessel Speed\n",
    "            if line[0:11] == \"Ship Speed:\":\n",
    "                obs = line.split()\n",
    "                self.vessel_speed=float(obs[2])/1.852\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B.0.2.5 Parsing the Record Identifier Line\n",
    "\n",
    "Now that we have parsed the header we can exit the `for` loop parsing the MVP file header in the `read_mvp_file()` method. The next type is to parse the last line of the header which identifies the type and units of the data contained in the columns of the data records.\n",
    "\n",
    "The first step is to split the last header line\n",
    "\n",
    "        rec_type = svp_lines[n_lines].split(',')\n",
    "    \n",
    "To find the index of the Depth records we can then use:\n",
    "\n",
    "        index_depth = rec_type.index('Dpth(m)') \n",
    "        \n",
    "Similary find the index for the Sound Speed records and assign them to `index_ss`\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B.0.2.6 Parsing the Records\n",
    "\n",
    "We can finally parse the data!  \n",
    "\n",
    "        for line in svp_lines[ n_lines + 1:]:\n",
    "            obs = line.split(',')\n",
    "            self.obs_depth.append( float(obs[index_depth]))\n",
    "            self.obs_ss.append( float(obs[index_ss]))\n",
    "\n",
    "Will read all the data records into the `SSP` data object.\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B.0.2.7 Sorting the Records\n",
    "\n",
    "Although we now have all the data, it is not a given that the data in the profile are sorted by depth. The records are written sequentially and so, *usually* each subsequent record has a greater depth associated to it. This is, however, not guaranteed! It may be that the MVP winch moved faster upwards than the probe was falling through the water, leading to a reversal in the recorded depths. To make sure that this is not the case you should sort the profile's observed depths and sound speeds by depth, this is achieved by the following code that sorts both lists simultaneously by the contents of the list `self.obs_depth`:\n",
    "\n",
    "        temp = sorted(zip(self.obs_depth, self.obs_ss), key=lambda x: x[0])\n",
    "        self.obs_depth, self.obs_ss = map(list, zip(*temp))\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B.0.2.8 Removing the Duplicates\n",
    "\n",
    "Much like there may be reversals there may be duplicates i.e., depths for which there is more than one observation. There are several approaches that you may take to deal with this. Ideally the sound speed values will be the same, but in reality they will probably differ slightly - this is actually an opportunity for quality control.\n",
    "\n",
    "However, we will take a simple approach here, we will simply take the first observation for a given depth and then remove the others, this may be achieved by adding the following to the end of the `read_mvp_file()` method:\n",
    "\n",
    "        # Remove any duplicate depths with associated sound speeds\n",
    "        d_p=self.obs_depth[0]\n",
    "        index = 0\n",
    "        unwanted = []\n",
    "        for d in self.obs_depth[1:]:\n",
    "            index += 1\n",
    "            if d == d_p:\n",
    "                unwanted.append(index)\n",
    "            d_p = d\n",
    "            \n",
    "        for e in sorted( unwanted, reverse = True):\n",
    "            del self.obs_depth[ e]\n",
    "            del self.obs_ss[ e]\n",
    "\n",
    "Make sure that you understand the code snippet given here and ask yourself why the duplicates should be removed in reverse order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B.0.2.9 Creating numpy Arrays\n",
    "\n",
    "For the processing it will be useful to use numpy arrays - we will create 3 of these arrays, namely `self.c`, `self.d` and `self.g` to hold the sound speeds the depths and the associated gradients respectively. Add these variables to the class definition and at the end of the `read_mvp_file` assign them values e.g., `self.d` may be assigned as follows:\n",
    "\n",
    "    self.d = np.array(self.obs_depth)\n",
    "    \n",
    "assign `self.c` in similar manner:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B.0.2.10 Extending the profiles to the Surface\n",
    "    \n",
    "The problem that may occur is that the transducer may rise above the level of the first sound speed observation. To address this we should extend the profile to the surface. To extend the velocities to the surface we face a bit of a conundrum as we do not have an observed value there i.e., we are extrapolating. We know that sound velocity profiles typically start close the surface. The surface waters are *usually* well mixed due to wave action, thus we may expect that the sound speed at the surface is the same as at the first sample in the profile:\n",
    "\n",
    "    \n",
    "        if self.d[0] > 0:\n",
    "            self.d = np.insert(self.d,0,0)\n",
    "            self.c = np.insert(self.c,0,self.c[0])\n",
    "            \n",
    "    \n",
    "Note that this assumption **fails** when there is no mixing at the surface - this is one of the reasons that surveying on calm seas can be problematic. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B.0.2.11 Calculating the Sound Speed Gradients\n",
    "  \n",
    "The variable `self.g` will be the gradient of soundspeed for the layers, that is:\n",
    "$$g_i=\\frac{c_{i+1}-c_{i}}{d_{i+1}-d_{i}} = \\frac{\\Delta c}{\\Delta d}$$\n",
    "\n",
    "You can implement $c_{i+1}-c_{i}$ as `self.c[1:] - self.c[0:-1])` without having to use a for loop; the depth differences may be determined similarly.\n",
    "\n",
    "Assign `self.g` the gradients as shown in the equation above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B.0.2.12 Expanding the Profiles to Full Ocean Depth\n",
    "  \n",
    "We also want to expand the profile to full ocean depth in case we have depth observations beyond the deepest sound speed sample. We may achieve this by making the assumption that the gradient is determined by the pressure effect alone (g=0.017$s^{-1}$). Add a block of code that adds the full ocean depth of 12,000m to the end of array `self.d`, the associated sound speed calculated using the gradient g=0.017$s^{-1}$ to the array `self.c` and the gradient used to the array `self.g`. **Only** do this if the greatest depth in the profile is smaller than 12,000m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B.0.2.13 Replacing Zero Gradients\n",
    "  \n",
    "For our calculation we will be using division by the gradients, to avoid numerical problems we want to replace zero values by a very small number. You may do this by the statement\n",
    "\n",
    "    self.g[self.g == 0] = 0.000001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B.0.2.14 Updating the profile\n",
    "  \n",
    "Now that we have updated the profile we need to update the sound speeds, otherwise the calculations will fail when encountering a layer that had zero sound speed gradient\n",
    "\n",
    "        # Recalculate the sound speed profile\n",
    "        \n",
    "        for i in range(1,len(self.g)):\n",
    "            self.c[i]=self.c[i-1]+(self.d[i] - self.d[i-1])*self.g[i-1]\n",
    "\n",
    "***NOTE that,even though the adjustments are very small, we are inherently biasing the profile here - there are better ways of doing this, but we want to keep the time spent on this lab reasonable***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B.1.3 Processing the Data - Estimating the Depth and Radial Distance Through Ray-Tracing\n",
    "\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"../Images/hor_strat.png\"><br><br>\n",
    "\n",
    "Now that we have the sound speed well conditioned and stored in a `SSP` object we are ready to start creating methods for interacting with the data. In Ocean Mapping the most common action is to determine the path of a ray using a starting depth at which the signal originated, a depression angle indicating the angle of departure and TWTT indicating the time of flight from transmission at the transducers to the seafloor and back. \n",
    "\n",
    "Given an initial beam-vector starting point (in depth) within a layered ocean as shown in the figure above, a vertically referenced depression angle, and a known two-way travel time to a bottom detection, we will now model:\n",
    "    \n",
    "    1 the depth below the starting point\n",
    "    2 the radial horizontal distance from the starting location\n",
    "    \n",
    "**Oceanographic Simplifications**\n",
    "\n",
    "Normally, the only sound speed profile information consists of a vertical section. No knowledge of the lateral variability of sound speed in the ocean is available. As a result, a simplifying assumption is usually made that the ocean consists only of horizontal layers with no lateral variability. The primary result of this assumption is that the beam azimuth will remain constant: that the ray only changes in depression angle as it penetrates through the layers.\n",
    "\n",
    "In reality, there are significant lateral sound speed gradients in the ocean. These can include: Oceanic fronts (e.g. the edge of the Gulf Stream or Kuroshiro) Tidal fronts (representing the boundary between mixed and stratified waters)\n",
    "River plume edges.\n",
    "\n",
    "The only way to cope with these is to make more frequent sound speed profiles. As time evolves or the ship moves, the ocean is obviously changing. There are strategies to gradually adjust the sound speed with space or time, but even under these circumstances, there is one simplifying assumption that is commonly made:\n",
    "\n",
    "        For the duration of a single ping, the sound speed structure does not change with azimuth. That is to say, a ray traced to the north, versus a ray to the west (or other azimuth), does not follow a different trajectory in the vertical plane.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B.1.3.0 Processing the Data\n",
    "\n",
    " To do this start by creating a method called `ray_trace()` that takes the arguments `d_start`, `th_start` and `twtt`\n",
    "\n",
    "The ray trace solution may proceed. This involves tracing the beam vector through the water column, accumulating traveled distance and time consumed in each layer of the ocean, until the TWTT is arrived at. At that point one has a measure of the vertical distance and radial distance in the vertical plane through which the ray has progressed.\n",
    "That vertical distance and radial horizontal distance may now be expressed as the total depth (adding the transducer draft), and along track and across track distance. Along and across track are X and Y horizontal axes aligned fore-aft and transverse to the transmitter position.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### B.1.3.0.0 Method for Determining Depths \n",
    "\n",
    "Now that we have the sound speed well conditioned and stored in a `SSP` object we are ready to start creating methods for interacting with the data. In Ocean Mapping the most common action is to determine the path of a ray using a starting depth at which the signal originated, a depression angle indicating the angle of departure and TWTT indicating the time of flight from transmission at the transducers to the seafloor and back. \n",
    "\n",
    "Create a method called `determine_depth()` for the `SSP` class that takes the arguments `d_start`, `th_start`, `ss_start` and `twtt`. In the method assign the variables `depth`, `rad_dist`, `layer_s` and `layer_e` all the value zero. return all the variables as a tuple using the statement\n",
    "\n",
    "    return depth, rad_dist, layer_s, layer_e; \n",
    "    \n",
    "If you did this correctly the code cell below should now execute, but all the values printed should be zero i.e., we still have to make it work correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import arccos, pi\n",
    "# depth, rad_dist, start, stop = ssp.determine_depth(4,20*pi/180,1464,0.2)\n",
    "# # depth,rad_dist,start_bin,stop_bin = ssp.determine_twtt(10,20)\n",
    "# print(\"Depth           : \"+str(depth))\n",
    "# print(\"Radial Distance : \"+str(rad_dist))\n",
    "# print(\"Start layer     : \"+str(start))\n",
    "# print(\"Stop layer      : \"+str(stop))\n",
    "# arccos(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.1.3.0.1 Determine the Start Layer\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"../Images/layer_indexing.png\"><br><br>\n",
    "\n",
    "The first task at hand is the determination of which layer `d_start` is located. Using the logic as indicated by the equation in B.0.2.9 result in indexing as shown in the figure above. For example if `self.d[0]`==0 and `self.d[1]`== 10 and d_start == 3 then the start layer `layer_s` == 0\n",
    "\n",
    "Just above the `return` statement assign the `layer_s` the correct value based on `self.d` and and `d_start`. the code cell below should now execute correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th: 0.349045898\n",
      "Start Layer 28  ranges from 9.92m to 10.12m\n",
      "Signal traversed 238 layer boundaries\n",
      "End Layer 266  ranges from 59.01m to 59.21m\n",
      "vertical distance from the surface is 59.03\n",
      "TWTT to top of end layer 0.1992s\n",
      "\n",
      "\n",
      "dt 0.001220625313158619\n",
      "Start depth 10m is contained in layer 28\n",
      "layer 28 spans the range 9.92m to 10.12m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-semmed/ESCI_OE_774_874/Lab_A/mycode/SSP.py:191: RuntimeWarning: invalid value encountered in arccos\n",
      "  th = arccos(self.c[0:]*ray_c)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "156.45000000000002"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_start=10\n",
    "depth, rad_dist, start, stop = ssp.determine_depth(d_start,20*pi/180,1464.5,0.2)\n",
    "print(\"Start depth \"+str(d_start)+\"m is contained in layer \"+str(start))\n",
    "print(\"layer \"+str(start)+\" spans the range \"+str(ssp.d[start])+\"m to \"+str(ssp.d[start+1])+\"m\" )\n",
    "\n",
    "d_start + 0.2*1464.5/2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.1.3.0.2 Determine the Ray Constant\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"../Images/steering_velocity.png\"><br><br>\n",
    "\n",
    "One of the operational problems you will face in the ray trace calculation is the fact that the sound speed at the face of the array (continuously measured and provided with each observation), may no longer match the sound speed measured at the array depth in the archived sound speed profile that you are using.\n",
    "\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"../Images/ss_mismatch.png\"><br><br>\n",
    "\n",
    "This would be because the sound speed profile was measured previously (back in time) and at a location other than the current position. The current *surface* sound speed (in fact measured at the depth of the array –see photo to bottom left), is logged continuously and recorded together with each swath. The sonar calculates the steering angle using the current surface sound speed. For this the **ray constant** is used, given by the equation:\n",
    "\n",
    "$$C_{ray}=\\frac{cos(\\theta_d)}{c_{start}}$$\n",
    "Where:<br>\n",
    "$C_{ray}$: Ray Constant<br>\n",
    "$\\theta_d$: Depression angle<br>\n",
    "$c_{start}$: Sound speed at transducer<br>\n",
    "\n",
    "In your `determine_depth` method calculate the ray constant `ray_c` using  `ss_start` and the depression angle `th_start`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.1.3.0.3 Calculate Ray Path Properties for Each Layer\n",
    "\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"../Images/ray_trace.png\"><br><br>\n",
    "\n",
    "If the sound speed gradient is constant in each layer then the ray path followed by the signal describes in the layers forms an *arc of circle* whose radius is defined by the radius as follows\n",
    "\n",
    "<br><br><img align=\"center\" width=\"60%\" style=\"padding-right:10px;\" src=\"../Images/r_curvature.png\"><br><br>\n",
    "\n",
    "From the figure (***there are some errors that need to be fixed!!***) we see that (**these are the correct equations**):\n",
    "\n",
    "\n",
    "$$R_{i}=\\frac{-c_i}{g_i\\cdot cos(\\theta_i)}=-(C_{ray}\\cdot g_i)^{-1}$$<br><br>\n",
    "$$\\theta_{i}=arccos(c_i\\cdot C_{ray})$$<br><br>\n",
    "$$\\Delta x_i=R_i\\cdot(sin(\\theta_{i+1})-sin(\\theta_i))$$<br><br>\n",
    "$$\\Delta d_i=d_{i+1}-d_{i}$$<br><br>\n",
    "$$H_i=\\frac1{g_i}\\cdot ln \\left(\\frac{c_{i+1}}{c_i}\\right)$$<br><br>\n",
    "$$\\Delta t_i=H_i+\\frac1{g_i}\\cdot ln \\left( \\frac{1+sin\\theta_i}{1+sin(\\theta_{i+1}}\\right)$$\n",
    "\n",
    "Where:<br>\n",
    "$i$: Index of the current layer, being layer `layer_s`<br>\n",
    "$R$: Radius of path curvature in layer i <br>\n",
    "$\\theta_i$: Depression angle at the top of layer i <br>\n",
    "$\\Delta x_i$: Radial distance traversed in layer i <br>\n",
    "$\\Delta d_i$: Vertical distance traversed in layer i <br>\n",
    "$H_i$: Harmonic mean sound speed for layer i <br>\n",
    "$\\Delta t_i$: The **one-way** travel time for traversing layer i <br><br>\n",
    "the formulation of these equations means that once we know the ray constant we can now calculate the ray parameters for **all** the layers without using a for loop. This is regardless of whether the signal actually traversed through the layer!\n",
    "\n",
    "For example we can can calculate all the layer thicknesses `delta_d` by using:\n",
    "\n",
    "    delta_d = self.d[1:] - self.d[0:-1]\n",
    "\n",
    "In similar manner calculate all radii of curvature `r_curve`, all depression angles `th`, horizontal distances `dx`, vertical distances `dz`, Harmonic means `hm` and two way travel times `dtwtt`. Don't forget that $\\Delta t$ is the one-way travel time!\n",
    "\n",
    "# ___\n",
    "<img align=\"left\" width=\"6%\" style=\"padding-right:10px;\" src=\"../Images/info.png\">\n",
    "\n",
    "`numpy.diff(self.d)` achieves the same result as `self.d[1:] - self.d[0:-1]`, this function is useful when needing to determine higher order differences e.g., `numpy.diff(self.d),2)` results in the second order difference for the array `self.d`\n",
    "# ___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___\n",
    "<img align=\"left\" width=\"6%\" style=\"padding-right:10px;\" src=\"../Images/info.png\"><br><br><br>\n",
    "If we transmit downwards then $\\theta_i > 0$, thus when $theta_i$ becomes zero it has reached a depth where the ray inverts and starts traveling upwards. We can calculate **all** locations where the reversals occur using the ray constant $C_r$ and $\\theta=0$:\n",
    "\n",
    "$$\\theta = 0\\Rightarrow$$<br>\n",
    "$$arccos(c_r\\cdot C_{ray})=0\\Rightarrow$$<br>\n",
    "$$c_r\\cdot C_{ray}=1$$<br>\n",
    "$$c_r=\\frac{1}{C_{ray}}$$\n",
    "\n",
    "Where:<br>\n",
    "$c_r$: Sound speed at which ray reversals occur<br>\n",
    "\n",
    "Knowing the above you may find all the layers in which ray path reversals occur for a given ray constant, thus you may alter this method to address this, here we will not do so, as the assignment will get too extensive. Not dealing with this will, however, potentially result in values $c_r\\cdot C_{ray}>1$ for which the arccos function is undefined.\n",
    "\n",
    "*You will at this point encounter a warning related to the numpy.arccos() function - this happens when the argument passed is >= 1, given the above you know that this happens when the ray has reversed in a layer. The numpy.arccos() function will return a nan in that case. See the example below*\n",
    "# ___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.6/site-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in arccos\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "a=arccos(1.1)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.1.3.0.4 Determine the Properties for First Layer\n",
    "\n",
    "The signal did not actually traverse through all layers - it originated in layer `layer_s` as determined in step B.1.3.0.1, and will reflect of the bottom before reaching the final layer boundary. To determine the radial distance and vertical distance traversed we then need to break up the analysis in three parts taking into account:\n",
    "\n",
    "    1. The path traversed in the first layer\n",
    "    2. The path traversed in the intervening layers\n",
    "    3. The path traversed in the final layer\n",
    "    \n",
    "We already know how the signal traversed the intervening layers, but we must analyze the start and end layers separately. We already know what the start layer is and must determine the end layer. To this end we will simply accumulate the two travel times from the start layer to the end layer, along with the horizontal and vertical distances. Once the accumulated TWTT exceeds the travel time `twtt` passed into the `SSP.determine_depth()` method we have reached the final layer.\n",
    "\n",
    "We will use `sum_dx`, `sum_dz`, and `sum_dt` respectively for the cumulative radial distance, vertical distance and two way travel time.\n",
    "\n",
    "To start off we will determine properties of the hypothetical path the signal would take to travel from the boundary of the start layer to the transducer located at d_start:\n",
    "\n",
    "    dx_init = r_curve[layer_s]*(sin(th_start)-sin(th[layer_s])\n",
    "    \n",
    "Similarly determine the values for `dz_init` and `dt_init` i.e., the vertical distance and the TWTT from the top of the start layer to the depth of the transducer respectively. (You may look at the example code in B 1.3.0.5 for inspiration)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.1.3.0.5 Accumulate From the Start Layer\n",
    "\n",
    "We already know how the signal traverses the layers, we will now accumulate the contributions of these layers through the `numpy.cumsum()` function starting at the start layer. This function takes a `numpy.array` argument and returns an array of equal size with the summed elements up to the index of the element e.g,  \n",
    "\n",
    "    np.cumsum(np.ones(4))\n",
    "    \n",
    "returns the `numpy.array`: [1., 2., 3., 4.]\n",
    "\n",
    "The advantage of using the cumulative sum is that we can see what the cumulated ray properties are at the boundary of each layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signal traversed 3.00m down from starting depth of 2.10m to a total depth of 5.10m\n",
      "\n",
      "Starting depth 2.10m is contained in layer 1\n",
      "This layer ranges from 2.00m to 4.00m\n",
      "\n",
      "The total profile depth is 2000.00m\n",
      "The profile depth from the start depth is 1997.90m\n",
      "\n",
      "The number of layer boundaries traversed: 1\n",
      "\n",
      "The ending depth of 5.10m is contained in layer 2\n",
      "This layer ranges from 4.00m to 6.00m\n",
      "\n",
      "The distance from the start layer boundary to d_start is 0.10m\n",
      "The distance traversed in the final layer is 1.10m\n",
      "\n",
      "Total distance traversed is 3.00m\n"
     ]
    }
   ],
   "source": [
    "## Example code illustrating the use of logic with numpy arrays and \n",
    "## the numpy.cumsum() function - you may use this as inspiration for the \n",
    "## implementation of the determine_depth() and determine_twtt() methods \n",
    "## of the SSP class\n",
    "## Semme J. Dijkstra\n",
    "\n",
    "# Let's have a signal that originates at d_start and ends at d_end \n",
    "# relative to d_start\n",
    "d_start = 2.1\n",
    "d_down = 3\n",
    "\n",
    "# Determine the end depth\n",
    "d_end = d_start+d_down\n",
    "\n",
    "# # Let's create a set of successive depth layers of 2m thickness\n",
    "# # mu, sigma = 2, 0.1  # mean an\n",
    "# # delta_d = np.random.normal(mu, sigma, 1000)\n",
    "delta_d = 2*np.ones(1000)\n",
    "# # Note that layers cannot have a thickness < 0\n",
    "# delta_d[delta_d < 0] = -delta_d[delta_d < 0]\n",
    "\n",
    "# # Nor can they have a thickness delta_d == 0\n",
    "# delta_d[delta_d == 0] = 2\n",
    "\n",
    "# # We can now find the depths of the boundaries using the cumulative \n",
    "# # sum. Note that we want to start at 0m\n",
    "depths = np.zeros(len(delta_d)+1)\n",
    "depths[1:] = np.cumsum(delta_d)\n",
    "\n",
    "# What layer contains the starting depth?\n",
    "layer_s = sum( d_start >= depths) - 1\n",
    "\n",
    "# The distances from the start layer to the next layers\n",
    "sum_d = np.cumsum(depths[layer_s+1:] - depths[layer_s:-1])\n",
    "\n",
    "# the distance from the start layer to the start depth \n",
    "d_init = d_start - depths[layer_s]\n",
    "\n",
    "# The total distance from d_start to all the following boundaries\n",
    "# sum_d += np.cumsum(delta_d[layer_s+1:])\n",
    "sum_d -= d_init\n",
    "\n",
    "# The number of layer boundaries the signal traverses\n",
    "n_bounds =  sum( d_down >= sum_d)\n",
    "\n",
    "# The layer that contains the depth d_end (greater than d_start i.e.,\n",
    "# with the assumption that the signal is travelling downward)\n",
    "layer_e =n_bounds+layer_s\n",
    "\n",
    "# # Note that I could also have used layer_e = sum( d_end >= depths)  - 1\n",
    "# # But you can use the same logic for the TWTTs with the way I implememted it \n",
    "\n",
    "# The distance in the end layer\n",
    "d_final = d_end - depths[layer_e]\n",
    "\n",
    "\n",
    "print(\"Signal traversed %.2fm down from starting depth of %.2fm to a total depth of %.2fm\"\\\n",
    "      %(d_down, d_start,d_start+d_down,))\n",
    "print(\"\\nStarting depth %.2fm is contained in layer %d\"%(d_start,layer_s))\n",
    "print(\"This layer ranges from %.2fm to %.2fm\"%(depths[layer_s],depths[layer_s+1]))\n",
    "print(\"\\nThe total profile depth is %.2fm\"%depths[-1])\n",
    "print(\"The profile depth from the start depth is %.2fm\"%sum_d[-1])\n",
    "print(\"\\nThe number of layer boundaries traversed: %d\"%n_bounds)\n",
    "print(\"\\nThe ending depth of %.2fm is contained in layer %d\"%(d_end,layer_e))\n",
    "print(\"This layer ranges from %.2fm to %.2fm\"%(depths[layer_e],depths[layer_e+1]))\n",
    "print(\"\\nThe distance from the start layer boundary to d_start is %.2fm\"%d_init)\n",
    "if n_bounds > 1 :\n",
    "    print(\"The distance traversed in the intervening layers is %.2fm\"%(sum_d[n_bounds-1]-d_init))\n",
    "print(\"The distance traversed in the final layer is %.2fm\"%d_final)\n",
    "if n_bounds != 0:\n",
    "    print(\"\\nTotal distance traversed is %.2fm\"%(sum_d[n_bounds-1]+d_final))\n",
    "else:\n",
    "    print(\"\\nTotal distance traversed is %.2fm\"%(d_final-d_init))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.1.3.0.6 Offset to the Start Depth\n",
    "\n",
    "In our case we want the cumulative sum of the properties of the starting layer and all successive layers (Assuming that the ray does not reverse, in which case you will have to use different logic). In the code cell above I have given an example of how you may want to address a problem like this.\n",
    "\n",
    "What we have so far is the cumulative vertical distance `sum_dz`, horizontal distance `sum_dx`, and TWTT `sum_dt` from the top of the start layer to the top of all the succeeding layers - we however want the cumulative sum from the location of the transducer i.e., we need to subtract the values found in step B 1.3.0.4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.1.3.0.7 Determine the Number of Boundaries Crossed and the End Layer Index\n",
    "\n",
    "Now that we have the total accumulated TWTT `sum_dt` from the transducer to the top of each layer we may find the layer in which the signal reaches the seafloor by comparing the TWTT `twtt` argument passed in to the method to the various TWTT. The first layer for which this value exceeds `twtt` is the layer below which the signal reflects back. Find the number of boundaries that the signal traversed and assign it to the `n_bounds` by analyzing the array `sum_dt`, note that `sum_dt[-1]` will be `nan` so exclude that from your analysis. Also note that the TWTT after this many boundaries *exceeds* the `twtt` passed in, so you have to subtract one.\n",
    "\n",
    "Now that you have determined the number of layer boundaries the signal traversed you can also determine the index the layer itself by offsetting it by the start layer `layer_s`, assign this to the variable `layer_e`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B.1.3.0.8 Determine Properties for the final layer from the top to the end\n",
    "\n",
    "<img align=\"left\" width=\"6%\" style=\"padding-right:10px;\" src=\"../Images/info.png\">In this step we will be using the `numpy` tangent `tan()`, arctangent `arctan()`, hyperbolic tangent `tanh()`, and hyperbolic arctangent arctanh() functions - to make your code less verbose you can add these to the `from numpy import ...` statement at the top of your `SSP.py` file. Note here that there are arguments for doing this, the primary one being the ability to write less verbose code; and against, the primary one there that it may not be obvious to other programmers where the methods and functions used originate from.  \n",
    "\n",
    "We now have the cumulative sums from the location of the transducer to the top of the layer in which the reflector is located e.g., the vertical distance is `sum_dz[layer_e]`. We now need to add the properties for the final layer.\n",
    "\n",
    "The depression angle $\\theta_{end}$ reached at the point of reflection may then be calculated from:<br><br>\n",
    "\n",
    "$$\\theta_{end} = 2*atan\\left(tanh\\left(\\frac{-t\\cdot g_i}{4}+atanh\\left(tan\\left(\\frac{\\theta_i}{2}\\right)\\right)\\right)\\right)$$\n",
    "\n",
    "<br>For one way travel times the 4 may be replaced by 2\n",
    "\n",
    "where:<br>\n",
    "$g_i$: sound speed gradient of the water mass<br>\n",
    "$t$: time the signal spent traversing water mass with gradient $g$ from the top<br>\n",
    "$\\theta_i$: depression angle of ray at the top of the layer\n",
    "\n",
    "*Note that a problem occurs when the signal reflects in the same layer as it originates: in this lab this situation does not occur so you do not have to test for it, but you can generalize your code to deal with this issue if you want\n",
    "\n",
    "assign the value of $\\theta_{end}$ to the variable `th_end`\n",
    "\n",
    "Now that you have the final depression angle you can determine the horizontal distance traversed in this layer using:\n",
    "\n",
    "$$\\Delta x_{end}=R_i\\cdot(sin\\theta_{end}-sin\\theta_i)$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\\Delta z_{end}=-R_i\\cdot(cos\\theta_{end}-cos\\theta_i)$$\n",
    "\n",
    "<br>assign the value of $\\Delta x_{end}$ to `dx_end` and the value of $\\Delta z_{end}$ to `dz_end`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### B.1.3.0.9 Return the results\n",
    "\n",
    "Now that you have all the information needed calculate the total horizontal distance traversed and assign it to the variable `depth` and the total vertical distance and assign it to the variable `rad_dist`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B.1.3.1 Calculating the TWTT for a Given Depth\n",
    "\n",
    "In the previous steps you calculated the depth and radial distance from a given start depth, depression angle and starting sound speed and a TWTT. Similarly you can calculate the TWTT given the terminal depth.\n",
    "\n",
    "Add the method `determine_twtt` to the `SSP` class. as follows:\n",
    "\n",
    "        def determine_twtt(self, d_start, th_start, ss_start, depth):\n",
    "        \n",
    "Now copy the contents of the the determine_depth() method up to step B.1.3.0.7, but replace the statement `depth=0` from B1.3.0.0 with `dist_z = depth - d_start` i.e., the vertical distance from the transducer to the bottom downward. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### B.1.3.1.0 Determine the Number of Boundaries Crossed and the End Layer Index\n",
    "\n",
    "Note that we interpret `depth` as the vertical distance from the surface to the value passed in. \n",
    "\n",
    "You now have all the properties of the ray path, but we need to determine the number of boundaries that the signal passed. Start by determining the index of the layer in which the bottom is reached an assign this to the variable `layer_e`. The simply find the number of boundaries `n_bounds` by offsetting `layer_e` with `layer_s`. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### B.1.3.1.1 Determine the Vertical Distance Traversed in the Last Layer\n",
    "\n",
    "Now that we know the index of the final layer we may determine the vertical distance the signal has traversed in this layer, assign this value to `d_z`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### B.1.3.1.2 Determine the Sound Speed at the End\n",
    "\n",
    "Use the vertical distance traversed in the last layer to calculate the sound speed `c_end` at the end."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### B.1.3.1.3 Determine the Depression Angle $\\theta_{end}$ At the End\n",
    "\n",
    "Use the sound speed `c_end` with the ray constant to determine the depression angle `th_end` at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "#### B.1.3.1.4 Determine the Total Two Way Travel Time\n",
    "\n",
    "Find the total TWTT by using the sum of the two way travel times `sum_dt` at boundary `layer_e` and adding the travel time in `layer_e` using $\\theta_{layer_{end}}$ and $\\theta_{end}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx_init: 0.549577727\n",
      "Start Layer 28  ranges from 9.92m to 10.12m\n",
      "Signal traversed 238 layer boundaries\n",
      "End Layer 266  ranges from 59.01m to 59.21m\n",
      "vertical distance from the surface is 59.03\n",
      "TWTT to top of end layer 0.1992s\n",
      "\n",
      "\n",
      "dt 0.001220625313158619\n",
      "A signal traverses from depth 10.00m in layer 28 for 0.20s and reaches the bottom at 59.03m in layer 266\n",
      "0.3367127847314754\n",
      "sum dt 0.1992\n",
      "0.015758933947779497\n",
      "Signal traversed 238 layer boundaries\n",
      "End Layer 266  ranges from 59.01m to 59.21m\n",
      "TWTT to top of end layer 0.2001s\n",
      "Depth to top of end layer 59.0100m\n",
      "-0.507723889369171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-semmed/ESCI_OE_774_874/Lab_A/mycode/SSP.py:191: RuntimeWarning: invalid value encountered in arccos\n",
      "  th = arccos(self.c[0:]*ray_c)\n",
      "/home/jupyter-semmed/ESCI_OE_774_874/Lab_A/mycode/SSP.py:283: RuntimeWarning: invalid value encountered in arccos\n",
      "  dz = delta_d\n"
     ]
    }
   ],
   "source": [
    "d_start = 10\n",
    "th_d = 20*pi/180\n",
    "c_start = 1464.5\n",
    "twtt = .2\n",
    "depth, rad_dist, start, stop = ssp.determine_depth(d_start,th_d,c_start,twtt)\n",
    "print('A signal traverses from depth %.2fm in layer %d for %.2fs and reaches the bottom at %.2fm in layer %d' \\\n",
    "      % (d_start,start, twtt, depth, stop))\n",
    "\n",
    "TWTT, start, stop = ssp.determine_twtt(d_start,th_d,c_start,depth)\n",
    "print((TWTT - twtt)*c_start/2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### B.2.3  Analyzing the Profiles\n",
    "\n",
    "Now that we have a method to read the mvp data files we will start processing them. The first task at hand is to create a class used to do this processing. You will find that there is a new class in the `Lab_A/mycode` folder that is called `AnalyzeSS`, which has as its descriptor \"\"\"A Class for Analyzing Sound Speed Data\"\"\" and, for now, has one list named SSPs meant for holding `SSP` objects.\n",
    "\n",
    "Now that we have a method to read the mvp data files we will start processing them. The first task at hand is to create a class used to do this processing. You will find that there is a new class in the `Lab_A/mycode` folder that is called `AnalyzeSS`, which has as its descriptor \"\"\"A Class for Analyzing Sound Speed Data\"\"\" and, for now, has one list named SSPs meant for holding `SSP` objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening sound speed profile data file:/home/jupyter-semmed/ESCI_OE_774_874/Lab_B/Data/Oct4_slope.112m1.txt\n",
      "Opening sound speed profile data file:/home/jupyter-semmed/ESCI_OE_774_874/Lab_B/Data/Oct4_slope.106m1.txt\n",
      "Opening sound speed profile data file:/home/jupyter-semmed/ESCI_OE_774_874/Lab_B/Data/Oct4_slope-1.103m1.txt\n",
      "Opening sound speed profile data file:/home/jupyter-semmed/ESCI_OE_774_874/Lab_B/Data/Oct4_slope.102m1.txt\n",
      "Opening sound speed profile data file:/home/jupyter-semmed/ESCI_OE_774_874/Lab_B/Data/Oct4_slope.113m1.txt\n",
      "Opening sound speed profile data file:/home/jupyter-semmed/ESCI_OE_774_874/Lab_B/Data/Oct4_slope.107m1.txt\n",
      "Opening sound speed profile data file:/home/jupyter-semmed/ESCI_OE_774_874/Lab_B/Data/Oct4_slope-1.102m1.txt\n",
      "Opening sound speed profile data file:/home/jupyter-semmed/ESCI_OE_774_874/Lab_B/Data/ssp.txt\n",
      "Opening sound speed profile data file:/home/jupyter-semmed/ESCI_OE_774_874/Lab_B/Data/Oct4_slope.103m1.txt\n"
     ]
    }
   ],
   "source": [
    "# Get a list of the files in the Data Directory\n",
    "\n",
    "data=Path('./Data/') # Get the path to your data folder\n",
    "ls=list(data.glob('*.txt')) # Get a list of data files holding sound speed profiles\n",
    "\n",
    "ana_ss = AnalyzeSS() # Create an AnalyzeSS for analysing the sound speed profiles\n",
    "\n",
    "# Add the SSPs to ana_ss for processing\n",
    "for f in ls:\n",
    "    # Create a new SSP object for the current data file\n",
    "    ssp=SSP()\n",
    "    \n",
    "    # Read the data file into the SSP\n",
    "    ssp.read_mvp_file(str(f.resolve()))\n",
    "    \n",
    "    # Add the SSP to the AnalyzeSS object\n",
    "    ana_ss.SSPs.append(ssp)\n",
    "    \n",
    "#     ana_ss.draw('Oct4_slope.112m1','Oct4_slope.106m1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do the analysis we need to read create an object for all the data files of interest and add it to the list `SSPs` in `AnalyzeSS`. The code cell above achieves this in a number of steps:\n",
    "\n",
    "    data=Path('./Data/')\n",
    "    \n",
    "creates a `Path` object named data pointing to the data directory of the current working directory (the `.` operator points at the current working directory). \n",
    "\n",
    "The `glob()` method finds all the pathnames matching the pattern '\\*.txt', where the `*` symbol is a wild card. Thus the line\n",
    "\n",
    "    ls=list(data.glob('*.txt'))\n",
    "    \n",
    "creates a `list` named `ls` with as its members the path of all the file names ending in '.txt' in the directory pointed at by `data`. \n",
    "\n",
    "    ana_ss = AnalyzeSS()\n",
    "    \n",
    "Creates the `AnalyzeSS` object named `ana_ss` which you will be using for the sound speed analysis.\n",
    "\n",
    "    for f in ls:\n",
    "    \n",
    "Establishes a loop that will loop through all the files pointed a by `f` in the list `ls` \n",
    "\n",
    "    ssp=SSP()\n",
    "        \n",
    "for each iteration of the loop a **new** SSP object is created.\n",
    "\n",
    "    ssp.read_mvp_file(str(f.resolve()))\n",
    "    \n",
    "Reads the data in the file pointed at by the `f` Path object. For this we need the fullpath of the file, which we find by using the `resolve()` method. Handling paths this way is nice as the `Path` will take care of the differences between operating systems e.g., the use of `/` in Linux vs `\\` in Windows.\n",
    "\n",
    "    ana_ss.SSPs.append(ssp)\n",
    "    \n",
    "Adds the newly created `SSP` object `ssp` to the list `ana_ss.SSPs`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ___\n",
    "<br>\n",
    "\n",
    "<img align=\"left\" width=\"6%\" style=\"padding-right:10px;\" src=\"../Images/test.png\">\n",
    "\n",
    "# Essay Questions\n",
    "\n",
    "<br>\n",
    "Answer the questions below in essay form. Keep the answers short and concise!\n",
    "\n",
    "    1. comment on whether the induced errors are significant compared \n",
    "       to IHO Order 1 required horizontal or vertical accuracies. \n",
    "       Note whether/how this compliance changes as a function of beam\n",
    "       angle.\n",
    "       \n",
    "    2. Why are the 4 data fields discussed in paragraph B.0 useful? \n",
    "    \n",
    "    3. Why are the duplicate records removed in reverse order in step B.0.2.8?\n",
    "    \n",
    "    4. In B.0.2.10 we extended the profiles upwards to the surface assuming \n",
    "       that the water near the surface is well mixed. Would this give a problem \n",
    "       on a calm and hot sunny afternoon? Explain your answer using the \n",
    "       word 'gradient' \n",
    "\n",
    "    5. in B.0.2.13 we replaced the zero values in the array self.g using the Boolean \n",
    "       vector self.g == 0 in the expression self.g[self.g == 0] = 0.00001. Explain what \n",
    "       this expression does.\n",
    "       \n",
    "    6. Unless you have adapted your code to deal with ray reversal you would have \n",
    "       received a warning when determining the depression angles 𝜃𝑖 in step \n",
    "       B.1.3.0.3. Assuming that you loaded the data contained in the file     \n",
    "       'Oct4_slope.112m1.txt' into an SSP object 'ssp' and called the method as follows \n",
    "       'ssp.determine_depth(d_start,20*pi/180,1464.5,0.2)'\n",
    "           a. From which layer does the warning originate? How do you know?\n",
    "           c. What is the sound speed at which this occurs?\n",
    "           b. At what depth in this layer does the ray reversal occur i.e., does it go \n",
    "              from going downward to upward?\n",
    "           d. Given the location of the survey do you think a ray reversal can occur in \n",
    "              reality for this signal? \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" width=\"6%\" style=\"padding-right:10px; padding-top:10px;\" src=\"../Images/refs.png\">\n",
    "\n",
    "## Useful References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [The official Python 3.6 documentation](https://docs.python.org/3.6/index.html)\n",
    "  * [Classes](https://docs.python.org/3.6/tutorial/classes.html)\n",
    "  * [String Representation Method](https://docs.python.org/3.6/reference/datamodel.html?highlight=repr#object.__str__)\n",
    "* [Memory address](https://en.wikipedia.org/wiki/Memory_address)\n",
    "* [ePOM: Programming Basics with Python](https://github.com/hydroffice/python_basics)\n",
    "* [ePOM: Foundations of Ocean Data Science](../../ocean_data_science)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" width=\"5%\" style=\"padding-right:10px;\" src=\"../Images/email.png\">\n",
    "\n",
    "*For issues or suggestions related to this notebook that should not be addressed on Piazza, write to: semmed@ccom.unh.edu*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab B Created by John E. Hughes Clarke<br>\n",
    "Python code and Jupyter Notebook implementation by Semme J. Dijkstra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'depth' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-efe7af9e32be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrad_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'depth' is not defined"
     ]
    }
   ],
   "source": [
    "depth, rad_dist, start, stop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
