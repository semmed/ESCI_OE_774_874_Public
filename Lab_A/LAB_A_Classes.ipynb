{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from numpy import pi, cos, sin, log, exp\n",
    "from scipy.interpolate import interp1d\n",
    "import numpy as np\n",
    "import os.path\n",
    "from datetime import datetime, timezone\n",
    "import pyproj as proj\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method for creating EPSG projection strings\n",
    "# This is provided as an example \n",
    "# If the data spans one zone return a string representing the EPSG projection code\n",
    "# If the data spans more than one zone return a list with as its first element the central zone as defined by\n",
    "# the range of the data, and as its other members the other zones in which data is contained\n",
    "\n",
    "\n",
    "def get_EPSG_projection_code(latitudes, longitudes, projection, ellipsoid):\n",
    "\n",
    "    # By default return None\n",
    "    epsg_codes = None\n",
    "\n",
    "    if not isinstance(projection, str):\n",
    "        raise RuntimeError(\n",
    "            'get_EPSG_projection_code(): argument `projection` must be of type str')\n",
    "  \n",
    "    if not isinstance(ellipsoid, str):\n",
    "        raise RuntimeError(\n",
    "            'get_EPSG_projection_code(): argument `ellipsoid` must be of type str')\n",
    "\n",
    "    if projection == 'UTC':\n",
    "\n",
    "        if ellipsoid != 'WGS84':\n",
    "            raise RuntimeError('get_EPSG_projection_code(): Currently the ellipsoid ' +\n",
    "                           str(ellipsoid)+' is not yet implemented')\n",
    "            \n",
    "        else:\n",
    "            ell_str='32'\n",
    "\n",
    "        if isinstance(latitudes, float) and isinstance(longitudes, float):\n",
    "\n",
    "            # Deal with the zones\n",
    "            zone = str(int(np.floor((longitudes + 180) / 6) % 60 + 1))\n",
    "\n",
    "            if len(zone) == 1:\n",
    "                zone = '0'+zone\n",
    "\n",
    "            # Deal with the hemispheres\n",
    "            if latitudes >= 0:\n",
    "                epsg_codes = ell_str+'6'+zone\n",
    "            else:\n",
    "                epsg_codes  =ell_str+'7'+zone\n",
    "\n",
    "        elif isinstance(latitudes, list) and isinstance(longitudes, list):\n",
    "\n",
    "            epsg_codes = list()\n",
    "\n",
    "            # Determine the central longitude and latitude\n",
    "            central_lon = (max(longitudes)+min(longitudes))/2\n",
    "            central_lat = (max(latitudes)+min(latitudes))/2\n",
    "\n",
    "            # Determine the UTM Zone from the central longitude\n",
    "            zone = str(int((np.floor((central_lon + 180) / 6) % 60) + 1))\n",
    "\n",
    "            if len(zone) == 1:\n",
    "                zone = '0'+zone\n",
    "\n",
    "            # Deal with the hemispheres\n",
    "            if central_lat >= 0:\n",
    "                zone = ell_str+'6'+zone\n",
    "            else:\n",
    "                zone = ell_str+'7'+zone\n",
    "\n",
    "            epsg_codes.append(zone)\n",
    "\n",
    "            ii = -1\n",
    "            # Determine the UTM zone for all points in the lists\n",
    "            for longitude in longitudes:\n",
    "\n",
    "                # Update the index\n",
    "                ii += 1\n",
    "\n",
    "                zone = str(int(np.floor((longitude + 180) / 6) % 60 + 1))\n",
    "\n",
    "                if len(zone) == 1:\n",
    "                    zone = '0'+zone\n",
    "\n",
    "                # Deal with the hemispheres\n",
    "                if latitudes[ii] >= 0:\n",
    "                    zone = ell_str+'6'+zone\n",
    "                else:\n",
    "                    zone = ell_str+'7'+zone\n",
    "\n",
    "                if zone not in epsg_codes:\n",
    "                    epsg_codes.append(zone)\n",
    "\n",
    "            if len(epsg_codes) != 1:\n",
    "                print('get_EPSG_projection_code(): Data spans more than one UTM zone!')\n",
    "\n",
    "        else:\n",
    "            raise RuntimeError(\n",
    "                'get_EPSG_projection_code(): latitudes and longitudes must be both of type `float` or `list`')\n",
    "\n",
    "    else:\n",
    "        raise RuntimeError('get_EPSG_projection_code(): Projection `' +\n",
    "                           projection+'` not yet implemented')\n",
    "\n",
    "    return epsg_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1.1 Water Level Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaterLevel:\n",
    "    \"\"\"A Class for handling Water Level Data\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # The data attributes\n",
    "        self.times = list()\n",
    "        self.water_levels = list()\n",
    "        self.metadata = dict()\n",
    "        self.metadata[\"units\"] = \"m\"\n",
    "        self.metadata[\"geoid\"] = None\n",
    "        self.metadata[\"ellipsoid\"] = None\n",
    "        self.metadata[\"chart_datum\"] = None\n",
    "        self.metadata[\"start_time\"] = None\n",
    "        self.metadata[\"end_time\"] = None\n",
    "        self.metadata[\"count\"] = None\n",
    "        self.metadata[\"time_basis\"] = \"UTC\"\n",
    "\n",
    "    # The I/O methods:\n",
    "\n",
    "    def read_jhc_file(self, fullpath):\n",
    "\n",
    "        # Check the File's existence\n",
    "        if os.path.exists(fullpath):\n",
    "            self.metadata[\"Source File\"] = fullpath\n",
    "            print('Opening water level data file:' + fullpath)\n",
    "            print(type(wl_lines))\n",
    "        else:  # Raise a meaningful error\n",
    "            raise RuntimeError('Unable to locate the input file' + fullpath)\n",
    "\n",
    "        # Open, read and close the file\n",
    "        wl_file = open(fullpath)\n",
    "        wl_content = wl_file.read()\n",
    "        wl_file.close\n",
    "\n",
    "        # Tokenize the contents\n",
    "        wl_lines = wl_content.splitlines()\n",
    "        count = 0  # initialize the counter for the number of rows read\n",
    "        for wl_line in wl_lines:\n",
    "            observations = wl_line.split()  # Tokenize the string\n",
    "            epoch=datetime.fromtimestamp(float(observations[5]), timezone.utc)\n",
    "            self.times.append(epoch)\n",
    "            self.water_levels.append(float(observations[6]))\n",
    "            count += 1\n",
    "        print(type(wl_lines))\n",
    "        \n",
    "    def draw(self):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        print('Drawing Water Level Data')\n",
    "  \n",
    "        # plotting the points  \n",
    "        plt.plot(self.times, self.water_levels) \n",
    "        plt.title('Water Levels in [m]') \n",
    "        plt.ylabel('Water Level in [m] →') \n",
    "        plt.xlabel('Time ('+self.metadata['time_basis']+') →') \n",
    "        plt.xticks(rotation='60')\n",
    "\n",
    "  \n",
    "        # giving a title to my graph \n",
    "        \n",
    "  \n",
    "        # function to show the plot \n",
    "        #plt.show() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Class Definition for Position Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Position:\n",
    "    \"\"\"A Class for handling Position Data\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # The data attributes\n",
    "        self.times = list()\n",
    "        \n",
    "        # The geodetic coordinates - these are curvilinear so do not put them\n",
    "        # in vectors, as that is a linear concept\n",
    "        self.latitudes = list()\n",
    "        self.longitudes = list()\n",
    "        self.ortho_heights = list()\n",
    "        self.proj_pos=np.array([])\n",
    "        self.metadata = dict()\n",
    "        self.data_path=str()\n",
    "        self.metadata[\"units\"] = \"m\"\n",
    "        self.metadata[\"geoid\"] = None\n",
    "        self.metadata[\"ellipsoid\"] = None\n",
    "        self.metadata[\"chart_datum\"] = None\n",
    "        self.metadata[\"start_time\"] = None\n",
    "        self.metadata[\"end_time\"] = None\n",
    "        self.metadata[\"count\"] = None\n",
    "        self.metadata[\"time_basis\"] = \"UTC\"\n",
    "        self.metadata[\"proj_str\"] = None\n",
    "\n",
    "    # The I/O methods:\n",
    "\n",
    "    def read_jhc_file(self, fullpath):\n",
    "\n",
    "        # Set the reference ellipsoid to WGS84\n",
    "\n",
    "        self.metadata[\"ellipsoid\"] = \"WGS84\"\n",
    "\n",
    "        # Check the File's existence\n",
    "        if os.path.exists(fullpath):\n",
    "            self.data_path = fullpath\n",
    "            print('Opening GNSS data file:' + fullpath)\n",
    "        else:  # Raise a meaningful error\n",
    "            raise RuntimeError('Unable to locate the input file' + fullpath)\n",
    "\n",
    "        # Open, read and close the file\n",
    "        gnss_file = open(fullpath)\n",
    "        gnss_content = gnss_file.read()\n",
    "        gnss_file.close\n",
    "        \n",
    "        times=list();\n",
    "\n",
    "        # Tokenize the contents\n",
    "        gnss_lines = gnss_content.splitlines()\n",
    "        count = 0  # initialize the counter for the number of rows read\n",
    "        for gnss_line in gnss_lines:\n",
    "            observations = gnss_line.split()  # Tokenize the string\n",
    "            time = datetime.fromtimestamp(\n",
    "                float(observations[5]), timezone.utc)\n",
    "            times.append(time)\n",
    "            self.latitudes.append(float(observations[8]))\n",
    "            self.longitudes.append(float(observations[7]))\n",
    "            self.ortho_heights.append(float(observations[6]))\n",
    "            count += 1\n",
    "\n",
    "        self.times=np.asarray(times)\n",
    "        \n",
    "        # Set the metadata\n",
    "        \n",
    "        self.metadata[\"chart_datum\"] = 'Orthometric'\n",
    "\n",
    "    def carto_project(self, projection_name, z_reference):\n",
    "\n",
    "        # start by creating a projection parameter string following PROJ protocol\n",
    "\n",
    "        if not isinstance(projection_name, str):\n",
    "            raise RuntimeError(\n",
    "                'Position.project(): argument `projection` must be of type str')\n",
    "\n",
    "        if self.metadata[\"ellipsoid\"] == None:\n",
    "            raise RuntimeError(\n",
    "                'Position.project(): Requires ellipsoid metadata to be defined!')\n",
    "\n",
    "        # Keep a list of projection that are implemented in this function\n",
    "        implemented_projections = list()\n",
    "        implemented_projections.append('utm')\n",
    "\n",
    "        # Raise an error of a non implemented projection is asked for\n",
    "        if projection_name.lower() not in implemented_projections:\n",
    "            raise RuntimeError(\n",
    "                'Position.project(): The projection `' + projection_name + '` is not yet implemented')\n",
    "            \n",
    "        # Universal will map to utm or ups depending on the central latitude\n",
    "        if projection_name.lower() == 'universal':\n",
    "            projection_name='utm'\n",
    "\n",
    "        if projection_name.lower() == 'utm':\n",
    "            proj_str = '+proj=utm'\n",
    "\n",
    "            # Determine the central longitude and latitude in degrees\n",
    "            central_lon = (max(self.longitudes)+min(self.longitudes))/2\n",
    "            central_lat = (max(self.latitudes)+min(self.latitudes))/2\n",
    "\n",
    "            # Determine the UTM Zone from the central longitude and latitude\n",
    "            proj_str += ' +zone=' + \\\n",
    "                str(int((np.floor((central_lon + 180) / 6) % 60) + 1))\n",
    "            if central_lat > 0:\n",
    "                proj_str += ' +north'\n",
    "            else:\n",
    "                proj_str += ' +south'\n",
    "\n",
    "            # The geodetic datum of the input coordinates\n",
    "            proj_str += ' +ellps=' + self.metadata[\"ellipsoid\"]\n",
    "\n",
    "            # The datum for the output coordinates\n",
    "            proj_str += ' +datum=' + self.metadata[\"ellipsoid\"]\n",
    "\n",
    "            # The units for the output coordinates\n",
    "            proj_str += ' +units=m'\n",
    "\n",
    "            # Prevent PROJ default behavior\n",
    "            proj_str += ' +no_defs'\n",
    "\n",
    "            # Create a pyproj object using proj_str\n",
    "            proj_obj = proj.Proj(proj_str)\n",
    "\n",
    "            # Perform the projection\n",
    "            E, N = proj_obj(self.longitudes, self.latitudes)\n",
    "            \n",
    "            # Create a matrix of positions as 3D column vectors\n",
    "            if z_reference.lower()=='ortho':\n",
    "                pos.proj_pos=np.asarray([np.asarray(E),np.asarray(N),np.asarray(self.ortho_heights)])\n",
    "            else:\n",
    "                raise RuntimeError('Position.carto_project(): currently only implemented for orthometric heights')\n",
    "            \n",
    "            # Add the string to the metadata\n",
    "            self.metadata['proj_str'] = proj_str\n",
    "            \n",
    "    def get_carto(self):\n",
    "        prj=''\n",
    "        zone=''\n",
    "        hemi=''\n",
    "        ellipse=''\n",
    "        datum=''\n",
    "        s_carto=self.metadata['proj_str']\n",
    "        for s in s_carto.split():\n",
    "            s=s.split('=')\n",
    "            if s[0] == '+proj':\n",
    "                prj=s[1]\n",
    "                print('he;;')\n",
    "            elif s[0] == '+zone':\n",
    "                zone=s[1]\n",
    "            elif s[0] == '+north':\n",
    "                 hemi = 'N'\n",
    "            elif s[0] == '+south':\n",
    "                 hemi = 'S'\n",
    "            elif s[0] == '+ellps':\n",
    "                 ellipse = s[1]\n",
    "            elif s[0] == '+datum':\n",
    "                 datum = s[1]\n",
    "           \n",
    "        if prj=='utm':\n",
    "            return 'UTM zone ' + zone + hemi + ' on ' + ellipse\n",
    "\n",
    "            \n",
    "    def draw(self, projection='auto'):\n",
    "\n",
    "        print('Drawing Positioning Data')\n",
    "\n",
    "        # Dertermine the central latitude nand longitude\n",
    "        central_lat = (max(self.latitudes)+min(self.latitudes))/2\n",
    "        central_lon = (max(self.longitudes)+min(self.longitudes))/2\n",
    "\n",
    "        # Create a 18x6 figure object\n",
    "        fig = plt.figure(figsize=(18, 6))\n",
    "\n",
    "        # Add a supertitle for the figure\n",
    "        fig.suptitle(\"Positioning Data\")\n",
    "\n",
    "        # Create an Orthographic coordinate reference system (crs)\n",
    "        crs_ortho = ccrs.Orthographic(central_lon, central_lat)\n",
    "\n",
    "        # Plot the globe using the just defined crs in the first plot in a row of two subplots\n",
    "        ax1 = fig.add_subplot(\n",
    "            1, 2, 1, projection=crs_ortho)\n",
    "        ax1.set_global()\n",
    "\n",
    "        # Add Oceans, land and graticule\n",
    "        ax1.add_feature(cartopy.feature.OCEAN)\n",
    "        ax1.add_feature(cartopy.feature.LAND, edgecolor='black')\n",
    "        ax1.gridlines()\n",
    "\n",
    "        # Set the title\n",
    "        ax1.set_title('Orthographic Map of Coverage Area')\n",
    "\n",
    "        # Indicate the general area of the Positions by plotting a black marker with white edges\n",
    "        # at the central latitude and longitude\n",
    "        plt.plot(central_lon, central_lat, marker='o', markersize=7.0, markeredgewidth=2.5,\n",
    "                 markerfacecolor='black', markeredgecolor='white',\n",
    "                 transform=crs_ortho)\n",
    "\n",
    "        # Set the zone number and hemisphere for the UTM projection\n",
    "        zone_number = int((np.floor((central_lon + 180) / 6) % 60) + 1)\n",
    "        if central_lat < 0:\n",
    "            southern_hemisphere = True\n",
    "        else:\n",
    "            southern_hemisphere = False\n",
    "\n",
    "        # Create an UTM reference system using the zone_number and hemisphere derived from the central coordinate\n",
    "        crs_utm = ccrs.UTM(\n",
    "            zone=zone_number, southern_hemisphere=southern_hemisphere)\n",
    "\n",
    "        # Plot the zone using the UTM crs in the second plot of the two subplots\n",
    "        ax2 = fig.add_subplot(\n",
    "            1, 2, 2, projection=crs_utm)\n",
    "        \n",
    "        # Set display limits based on the extend of the geodetic coordinates in this object\n",
    "        e_buffer=(np.max(self.longitudes)-np.min(self.longitudes))/10\n",
    "        n_buffer=(np.max(self.latitudes)-np.min(self.latitudes))/5\n",
    "        ax2.set_extent((np.min(self.longitudes)-e_buffer, np.max(self.longitudes)+e_buffer, np.min(\n",
    "            self.latitudes)-n_buffer, np.max(self.latitudes)+n_buffer), crs=crs_utm)\n",
    "\n",
    "        # Add Oceans, land and graticule\n",
    "        ax2.add_feature(cartopy.feature.OCEAN, zorder=0)\n",
    "        ax2.add_feature(cartopy.feature.LAND, zorder=0, edgecolor='black')\n",
    "        ax2.gridlines()\n",
    "        \n",
    "        # Set the title \n",
    "        ax2.set_title('UTM Map of Positioning Data')\n",
    "\n",
    "\n",
    "        # Plot all the positions as black dots\n",
    "        for lon, lat in zip(self.longitudes, self.latitudes):\n",
    "            plt.plot(lon, lat, marker='.', markersize=2.0,\n",
    "                     markerfacecolor='black', transform=crs_utm)\n",
    "\n",
    "        # Display the figure\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Class Definition for TWTT Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EchoSounderData:\n",
    "    \"\"\"A Class for handling Two Way Travel Time Data\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # The data attributes\n",
    "        self.times = np.array([])\n",
    "        self.twtts = np.array([])\n",
    "        self.metadata = dict()\n",
    "        self.metadata[\"units\"] = \"s\"\n",
    "        self.metadata[\"start_time\"] = None\n",
    "        self.metadata[\"end_time\"] = None\n",
    "        self.metadata[\"count\"] = None\n",
    "        self.metadata[\"time_basis\"] = \"UTC\"\n",
    "        self.metadata[\"Source_File\"]=str()\n",
    "        \n",
    "    # The I/O methods:\n",
    "\n",
    "    def read_jhc_file(self, fullpath):\n",
    "\n",
    "        # Check the File's existence\n",
    "        if os.path.exists(fullpath):\n",
    "            self.metadata[\"Source File\"] = fullpath\n",
    "            print('Opening Two Way Travel Time (TWTT) data file:' + fullpath)\n",
    "        else:  # Raise a meaningful error\n",
    "            raise RuntimeError('Unable to locate the input file' + fullpath)\n",
    "\n",
    "        # Open, read and close the file\n",
    "        twtt_file = open(fullpath)\n",
    "        twtt_content = twtt_file.read()\n",
    "        twtt_file.close\n",
    "        \n",
    "        times=list()\n",
    "        twtts=list()\n",
    "        \n",
    "        # Tokenize the contents\n",
    "        twtt_lines = twtt_content.splitlines()\n",
    "        count = 0  # initialize the counter for the number of rows read\n",
    "        for twtt_line in twtt_lines:\n",
    "            observations = twtt_line.split()  # Tokenize the string\n",
    "            #time=datetime.fromtimestamp(float(observations[5]), timezone.utc)\n",
    "            times.append(datetime.fromtimestamp(float(observations[5]), timezone.utc))\n",
    "            twtts.append(float(observations[6]))\n",
    "            count += 1\n",
    "            \n",
    "        self.times=np.asarray(times)\n",
    "        self.twtts=np.array(twtts)\n",
    "     \n",
    "    def draw(self):\n",
    "        plt.figure(figsize=(10, 10))\n",
    "        print('Drawing TWTT Data')\n",
    "     # plotting the points  \n",
    "        plt.plot(self.times, self.twtts) \n",
    "        plt.title('Two Way Travel Times in [s]') \n",
    "        plt.ylabel('TWTT in [s] →') \n",
    "        plt.xlabel('Time time ('+self.metadata['time_basis']+') →') \n",
    "        plt.xticks(rotation='60')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Class Definition for Motion Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Motion:\n",
    "    \"\"\"A Class for handling motion Data\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # The data attributes\n",
    "        self.times = list()\n",
    "        self.yaw = list()\n",
    "        self.roll = list()\n",
    "        self.pitch = list()\n",
    "        self.heave = list()\n",
    "        self.metadata = dict()\n",
    "        self.metadata[\"units\"] = \"rad\"\n",
    "        self.metadata[\"start_time\"] = None\n",
    "        self.metadata[\"end_time\"] = None\n",
    "        self.metadata[\"count\"] = None\n",
    "        self.metadata[\"time_basis\"] = \"UTC\"\n",
    "\n",
    "    # The I/O methods:\n",
    "\n",
    "    def read_jhc_file(self, fullpath):\n",
    "\n",
    "        # Check the File's existence\n",
    "        if os.path.exists(fullpath):\n",
    "            self.metadata[\"Source File\"] = fullpath\n",
    "            print('Opening motion data file:' + fullpath)\n",
    "        else:  # Raise a meaningful error\n",
    "            raise RuntimeError('Unable to locate the input file' + fullpath)\n",
    "\n",
    "        # Open, read and close the file\n",
    "        motion_file = open(fullpath)\n",
    "        motion_content = motion_file.read()\n",
    "        motion_file.close\n",
    "\n",
    "        # Tokenize the contents\n",
    "        motion_lines = motion_content.splitlines()\n",
    "        count = 0  # initialize the counter for the number of rows read\n",
    "        for motion_line in motion_lines:\n",
    "            observations = motion_line.split()  # Tokenize the string\n",
    "            time = datetime.fromtimestamp(\n",
    "                float(observations[5]), timezone.utc)\n",
    "            self.times.append(time)\n",
    "            self.yaw.append(float(observations[6])*pi/180)\n",
    "            self.roll.append(float(observations[7])*pi/180)\n",
    "            self.pitch.append(float(observations[8])*pi/180)\n",
    "            self.heave.append(float(observations[9]))\n",
    "            count += 1\n",
    "\n",
    "    def draw(self):\n",
    "        print('Drawing Motion Data')\n",
    "        plt.figure(figsize=(20, 10))\n",
    "        ax1 = plt.subplot(4, 1, 1)\n",
    "        plt.plot(self.times, np.degrees(self.yaw))\n",
    "        plt.ylabel('Heading [deg] →')\n",
    "        ax2 = plt.subplot(4, 1, 2, sharex=ax1)\n",
    "        plt.plot(self.times, self.heave)\n",
    "        plt.ylabel('Heave [m] →')\n",
    "        ax3 = plt.subplot(4, 1, 3, sharex=ax1)\n",
    "        plt.plot(self.times, np.degrees(self.roll))\n",
    "        plt.ylabel('Roll [deg] →')\n",
    "        ax4 = plt.subplot(4, 1, 4, sharex=ax1, sharey=ax3)\n",
    "        plt.plot(self.times, np.degrees(self.pitch))\n",
    "        plt.ylabel('Pitch [deg] →')\n",
    "        plt.xlabel('Time ('+self.metadata['time_basis']+') →')\n",
    "        plt.xticks(rotation='60')\n",
    "\n",
    "        plt.setp(ax1.get_xticklabels(), visible=False)\n",
    "        plt.setp(ax2.get_xticklabels(), visible=False)\n",
    "        plt.setp(ax3.get_xticklabels(), visible=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Class Definition for Sound Speed Profile Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SSP:\n",
    "    \"\"\"A Class for handling Sound Speed Profile data\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # The data attributes\n",
    "        self.obs_time = None\n",
    "        self.log_time = None\n",
    "        self.obs_latitude = None\n",
    "        self.obs_longitude = None\n",
    "        self.vessel_latitude = None\n",
    "        self.vessel_longitude = None\n",
    "        self.obs_sample = list()\n",
    "        self.obs_depth = list()\n",
    "        self.obs_ss = list()\n",
    "        self.proc_ss = np.array([])\n",
    "        self.twtt_layer=np.array([])\n",
    "\n",
    "        self.metadata = dict()\n",
    "        self.metadata[\"units\"] = \"rad\"\n",
    "        self.metadata[\"count\"] = None\n",
    "        self.metadata[\"geoid\"] = None\n",
    "        self.metadata[\"ellipsoid\"] = None\n",
    "        self.metadata[\"chart_datum\"] = None\n",
    "        self.metadata[\"time_basis\"] = \"UTC\"\n",
    "\n",
    "    # The I/O methods:\n",
    "\n",
    "    def read_jhc_file(self, fullpath):\n",
    "\n",
    "        # Check the File's existence\n",
    "        if os.path.exists(fullpath):\n",
    "            self.metadata[\"Source File\"] = fullpath\n",
    "            print('Opening sound speed profile data file:' + fullpath)\n",
    "        else:  # Raise a meaningful error\n",
    "            raise RuntimeError('Unable to locate the input file' + fullpath)\n",
    "\n",
    "        # Open, read and close the file\n",
    "        motion_file = open(fullpath)\n",
    "        motion_content = motion_file.read()\n",
    "        motion_file.close\n",
    "\n",
    "        # Tokenize the contents\n",
    "        motion_lines = motion_content.splitlines()\n",
    "        self.obs_time = datetime.fromtimestamp(\n",
    "            float(motion_lines[1].split()[0]), timezone.utc)\n",
    "        self.log_time = datetime.fromtimestamp(\n",
    "            float(motion_lines[2].split()[0]), timezone.utc)\n",
    "        self.obs_latitude = float(motion_lines[3].split()[0])\n",
    "        self.obs_longitude = float(motion_lines[3].split()[1])\n",
    "        self.vessel_latitude = float(motion_lines[4].split()[0])\n",
    "        self.vessel_longitude = float(motion_lines[4].split()[1])\n",
    "        self.metadata[\"count\"] = int(motion_lines[5].split()[0])\n",
    "\n",
    "        count = 0  # initialize the counter for the number of rows read\n",
    "\n",
    "        for motion_line in motion_lines[16:]:\n",
    "            observations = motion_line.split()  # Tokenize the stringS\n",
    "            self.obs_sample.append(float(observations[0]))\n",
    "            self.obs_depth.append(float(observations[1]))\n",
    "            self.obs_ss.append(float(observations[2]))\n",
    "            count += 1\n",
    "\n",
    "        if self.metadata[\"count\"] != count:\n",
    "            raise RuntimeError('Nr of Samples read ('+str(count) +\n",
    "                               ') does not match metadata count (' +\n",
    "                               str(self.metadata[\"count\"])+')')\n",
    "\n",
    "        # Process the data - in the jhc data files this is already a one-way profile,\n",
    "        # this just for illustration\n",
    "        self.proc_ss = np.zeros((count, 3))\n",
    "\n",
    "        # Sort the data samples by depth\n",
    "        sorted_ss = sorted(zip(self.obs_depth, self.obs_ss))\n",
    "\n",
    "        layer = 0\n",
    "        for d, ss in sorted_ss:\n",
    "            self.proc_ss[[layer], [0]] = d\n",
    "            self.proc_ss[[layer], [1]] = ss\n",
    "            layer += 1\n",
    "\n",
    "        # Identify all the depths for which there are multiple observations\n",
    "        mask = np.full((count, 1), True)\n",
    "        mask[1:, [0]] = np.diff(self.proc_ss[:, [0]], axis=0) != 0\n",
    "\n",
    "        # Remove the duplicates - You really should get statistical representations here\n",
    "        # but to keep this short just remove the duplicates\n",
    "        self.proc_ss = self.proc_ss[mask[:, 0], ...]\n",
    "\n",
    "        # Determine the gradients - Note the indexing: the gradient of the first layer \n",
    "        # is contained at the same index as the data for the TOP of the layer.\n",
    "        self.proc_ss[0:-1, [2]] = np.diff(self.proc_ss[:, [1]],\n",
    "                                          axis=0)/np.diff(self.proc_ss[:, [0]], axis=0)\n",
    "\n",
    "        # Estimate gradient for last layer assuming that the temperature and salinity remain the same\n",
    "        # gradient solely a function of pressure (depth)\n",
    "        self.proc_ss[-1, [2]] = 0.017\n",
    "\n",
    "        # Extend to 12000 m if necesarry - this is to get around some manufcturers requirements\n",
    "        if self.obs_depth[-1] < 12000:\n",
    "            ss = self.proc_ss[-1:, [1]] + self.proc_ss[-1:, [2]] \\\n",
    "             * (12000-self.proc_ss[-1:, [0]])\n",
    "            self.proc_ss = np.vstack((self.proc_ss, [12000, ss, 0.017]))\n",
    "\n",
    "        # Extend to 0 m if necesarry - assume well mixed\n",
    "        if self.obs_depth[0] > 0:\n",
    "            self.proc_ss = np.vstack(\n",
    "                ([0, self.proc_ss[0, [1]], 0.], self.proc_ss))\n",
    "            \n",
    "        # Step 5 Create a look-up array of twtts for each full layer\n",
    "        # Allows for great gain in efficiency (do not have to calculate for each ping)\n",
    "        self.twtt_layer = np.zeros((count, 1))\n",
    "        \n",
    "        for layer in range(0,self.metadata[\"count\"]-1):\n",
    "            if self.proc_ss[layer, [2]] == 0:\n",
    "                self.twtt_layer[layer] = 2 * \\\n",
    "                    (self.proc_ss[layer+1, [0]] - self.proc_ss[layer, [0]])/ \\\n",
    "                     self.proc_ss[layer, [1]]\n",
    "            else:\n",
    "                self.twtt_layer[layer] = 2 / self.proc_ss[layer, [2]] * \\\n",
    "                 log(self.proc_ss[layer+1, [1]]/self.proc_ss[layer, [1]])\n",
    "\n",
    "    def depth(self, start_depth, twtt):\n",
    "        # Determine depth relative to the transducer for vertical incidence data \n",
    "        # using the harmonic mean sound speed\n",
    "\n",
    "        # Find the index to the start layer using Boolean logic\n",
    "        # Note that the profile is extended to full ocean depth\n",
    "        # As layer is indexed by the top depth this is a guarantee that there is a next layer\n",
    "        start_i = sum(start_depth >= self.proc_ss[:, [0]])-1\n",
    "        start_i = int(start_i[0])  # Turn the index into an integer\n",
    "\n",
    "        # The sound speed at the top of the layer\n",
    "        c_start=self.proc_ss[start_i, [1]]\n",
    "        \n",
    "        # Calculate the time it takes to get through this layer - avoid division by zero\n",
    "        if self.proc_ss[start_i, [2]] == 0:\n",
    "            twtt_layer = 2*(self.proc_ss[start_i+1, [0]] - \\\n",
    "                start_depth)/self.proc_ss[start_i, [1]]\n",
    "        else:\n",
    "            # Update c_start to comepensate for the change in speed to the transducer depth\n",
    "            c_start += self.proc_ss[start_i, [2]]*(start_depth-self.proc_ss[start_i, [0]])\n",
    "            \n",
    "            twtt_layer = 2/self.proc_ss[start_i, [2]] * \\\n",
    "             log(self.proc_ss[start_i+1, [1]]/c_start)\n",
    "            \n",
    "        # Create a cumulative sum of the contributions of each layer\n",
    "        twtt_cum=np.zeros((self.metadata[\"count\"]))\n",
    "        twtt_cum[start_i+1]=twtt_layer\n",
    "        twtt_cum[start_i+2:]=twtt_layer+np.cumsum(self.twtt_layer[start_i+2:])\n",
    "        \n",
    "        # Determine where twtt_cum starts to exceed twtt using Boolean logic\n",
    "        end_i=np.max(np.where(twtt_cum<twtt),axis=1)\n",
    "\n",
    "        # Deal with the twtt in the final layer. There are two cases \n",
    "        # 1) the signal originated in a higher layer \n",
    "        # 2) the signal originated in the same layer  \n",
    "        \n",
    "        if start_i!=end_i:\n",
    "            twtt_last=(twtt-twtt_cum[end_i])\n",
    "            d_start=self.proc_ss[end_i, [0]]\n",
    "        else: \n",
    "            twtt_last=twtt\n",
    "            d_start=start_depth\n",
    "            \n",
    "        if  self.proc_ss[[end_i], [2]]!=0:\n",
    "            # gradient is non-zero\n",
    "            # From twtt=2/g*log(C2/C1) => C2=C1*exp(g*twtt/2)\n",
    "            c_end = c_start*exp( self.proc_ss[end_i, [2]]*twtt_last/2)\n",
    "            \n",
    "            # The associated depth\n",
    "            depth = d_start + (c_end-c_start)/self.proc_ss[end_i, [2]]\n",
    "            \n",
    "        else:\n",
    "            # gradient is zero\n",
    "            depth=d_start + self.proc_ss[end_i, [1]]*twtt_last/2\n",
    "\n",
    "        # the depth is relative to the instantaneous (heaving) water surface, \n",
    "        # bring the value back to the transducer.\n",
    "        \n",
    "        depth-=start_depth   \n",
    "        return depth\n",
    "\n",
    "    def draw(self, full_profile=False):\n",
    "        print('Drawing Sound Speed Data')\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        ax1 = plt.subplot(1, 3, 1)\n",
    "        if full_profile:\n",
    "            plt.plot(self.obs_ss[0:], self.obs_depth[0:])\n",
    "        else:\n",
    "            plt.plot(self.obs_ss[0:-1], self.obs_depth[0:-1])\n",
    "\n",
    "        plt.ylabel('← Depth [m]')\n",
    "        plt.xlabel('Sound Speed [m/s] →')\n",
    "        ax1.invert_yaxis()\n",
    "        ax1.xaxis.tick_top()\n",
    "        ax1.xaxis.set_label_position('top')\n",
    "\n",
    "        ax2 = plt.subplot(1, 3, 2)\n",
    "        if full_profile:\n",
    "            plt.plot(self.proc_ss[0:, [2]], self.proc_ss[0:, [0]])\n",
    "        else:\n",
    "            plt.plot(self.proc_ss[0:-1, [2]], self.proc_ss[0:-1, [0]])\n",
    "\n",
    "        plt.ylabel('← Depth [m]')\n",
    "        plt.xlabel('Sound Speed Gradient [1/s] →')\n",
    "        ax2.invert_yaxis()\n",
    "        ax2.xaxis.tick_top()\n",
    "        ax2.xaxis.set_label_position('top')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Vessel:\n",
    "    \"\"\"A Class for handling Vessel Specific Data\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # The metadata\n",
    "        self.metadata = dict()\n",
    "        self.metadata[\"name\"]=str()\n",
    "        self.metadata[\"ownedby\"]=str()\n",
    "        self.metadata[\"operatedby\"]=str()\n",
    "    \n",
    "        # Quantitative data\n",
    "        self.lever_arm_trans =  np.array([])\n",
    "        self.lever_arm_rec =  np.array([])\n",
    "        self.lever_arm_pos = np.array([])\n",
    "        self.lever_arm_mru = np.array([])        \n",
    "        wl=[]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Integration:\n",
    "    \"\"\"A Class for Integrating Data to Create Soundings\"\"\"\n",
    "\n",
    "    def __init__(self, twtt, pos, motions, sound_speed_profile, water_levels, vessel):\n",
    "        \n",
    "        # For now we can only integrate if the Positions have been projected - we will use \n",
    "        # either UTM or UPS depending on the latitude\n",
    "        \n",
    "        if not pos.proj_pos.any():\n",
    "            pos.carto_project('universal')\n",
    "        \n",
    "        # The variables passed in\n",
    "        self.twtt=twtt\n",
    "        self.pos_ant=pos\n",
    "        self.motions=motions\n",
    "        self.ssp=sound_speed_profile\n",
    "        self.water_levels=water_levels\n",
    "        self.vessel=vessel\n",
    "        \n",
    "        # The number of twtts\n",
    "        n_twtt_times = len(twtt.times)\n",
    "\n",
    "        # the variables determined in the integration\n",
    "        self.R_tx = list()\n",
    "        self.R_rx = list()\n",
    "        self.lever_arm_pos_tx=np.zeros([3,n_twtt_times])\n",
    "        self.lever_arm_pos_rx=np.zeros([3,n_twtt_times])\n",
    "        self.lever_arm_trans_tx=np.zeros([3,n_twtt_times])\n",
    "        self.lever_arm_rec_rx=np.zeros([3,n_twtt_times])\n",
    "        self.pos_rp_tx=np.zeros([3,n_twtt_times])\n",
    "        self.pos_rp_rx=np.zeros([3,n_twtt_times])\n",
    "        self.pos_trans_tx=np.zeros([3,n_twtt_times])\n",
    "        self.pos_rec_rx=np.zeros([3,n_twtt_times])\n",
    "              \n",
    "\n",
    "        # Determine the transmit times as posix times\n",
    "        t_twtt = np.array([e.timestamp() for e in twtt.times])\n",
    "\n",
    "        # Obtaine the times of the various observed data as posix times\n",
    "        t_pos = np.array([e.timestamp() for e in pos.times])\n",
    "        t_mru = np.array([e.timestamp() for e in motions.times])\n",
    "        t_wl = np.array([e.timestamp() for e in water_levels.times])\n",
    "        \n",
    "        # Determine the interpolation function for the positions\n",
    "        f=interp1d(t_pos,pos.proj_pos,bounds_error=False)\n",
    "        \n",
    "        # Interpolate for the time of transmit\n",
    "        # Offset the heading by pi/2 to align axes\n",
    "        self.pos_proj_ant_tx=f(t_twtt)\n",
    "        self.p_tx = np.interp(t_twtt, t_mru, motions.pitch)\n",
    "        self.r_tx = np.interp(t_twtt, t_mru, motions.roll)\n",
    "        self.y_tx = np.interp(t_twtt, t_mru, motions.yaw)\n",
    "        self.h_tx = np.interp(t_twtt, t_mru, motions.heave)\n",
    "        self.wl_tx = np.interp(t_twtt, t_wl, water_levels.water_levels)\n",
    "\n",
    "        # Determine the reception times as posix times\n",
    "        t_twtt += twtt.twtts\n",
    "\n",
    "        # Interpolate for the time of reception\n",
    "        self.pos_proj_ant_rx=f(t_twtt)\n",
    "        self.p_rx = np.interp(t_twtt, t_mru, motions.pitch)\n",
    "        self.r_rx = np.interp(t_twtt, t_mru, motions.roll)\n",
    "        self.y_rx = np.interp(t_twtt, t_mru, motions.yaw)\n",
    "        self.h_rx = np.interp(t_twtt, t_mru, motions.heave)\n",
    "        self.wl_rx = np.interp(t_twtt, t_wl, water_levels.water_levels)\n",
    "\n",
    "        # For each ping (twtt) determine a sounding solution\n",
    "        ping = 0\n",
    "        self.depth = np.zeros((n_twtt_times))\n",
    "        self.la_trans_rec_txrx = np.zeros((3,n_twtt_times))\n",
    "\n",
    "\n",
    "        for t in t_twtt:\n",
    "\n",
    "            # Calculate the right-handed Euclidean Euler andgle Rotation matrices at the\n",
    "            # time of transmit around the x,y and z axes\n",
    "            Rx_tx = np.array([[1, 0,                     0                   ],\n",
    "                              [0, cos(self.r_tx[ping]), -sin(self.r_tx[ping])],\n",
    "                              [0, sin(self.r_tx[ping]),  cos(self.r_tx[ping])]])\n",
    "\n",
    "            Ry_tx = np.array([[cos(self.p_tx[ping]),  0, sin(self.p_tx[ping]) ],\n",
    "                              [0,                     1,  0                   ],\n",
    "                              [-sin(self.p_tx[ping]), 0,  cos(self.p_tx[ping])]])\n",
    "\n",
    "            Rz_tx = np.array([[cos(self.y_tx[ping]), -sin(self.y_tx[ping]), 0],\n",
    "                              [sin(self.y_tx[ping]),  cos(self.y_tx[ping]), 0],\n",
    "                              [0,                     0,                    1]])\n",
    "\n",
    "            # Calculate the total rotation matrix at transmit in the order x, y, z\n",
    "            self.R_tx.append( Rz_tx@Ry_tx@Rx_tx)\n",
    "\n",
    "            # Rotation matrices at time of reception\n",
    "            Rx_rx = np.array([[1, 0,                     0                   ],\n",
    "                              [0, cos(self.r_rx[ping]), -sin(self.r_rx[ping])],\n",
    "                              [0, sin(self.r_rx[ping]),  cos(self.r_rx[ping])]])\n",
    "\n",
    "            Ry_rx = np.array([[cos(self.p_rx[ping]),  0,  sin(self.p_rx[ping])],\n",
    "                              [0,                     1,  0                   ],\n",
    "                              [-sin(self.p_rx[ping]), 0,  cos(self.p_rx[ping])]])\n",
    "\n",
    "            Rz_rx = np.array([[cos(self.y_rx[ping]), -sin(self.y_rx[ping]), 0],\n",
    "                              [sin(self.y_rx[ping]),  cos(self.y_rx[ping]), 0],\n",
    "                              [0,                     0,                    1]])\n",
    "\n",
    "            # Calculate the total rotation matrix at receive in the order x, y, z\n",
    "            self.R_rx.append( Rz_rx@Ry_rx@Rx_rx)\n",
    "\n",
    "            # Calculate the georeferenced lever_arms at the transmit times\n",
    "            # i.e., rotate the vessel lever arms using the rotation matrix R_tx\n",
    "            self.lever_arm_pos_tx[:,[ping]]=self.R_tx[ping]@vessel.lever_arm_pos\n",
    "            self.lever_arm_trans_tx[:,[ping]]=self.R_tx[ping]@vessel.lever_arm_trans\n",
    "\n",
    "            # Calculate the geo referenced lever_arms at the reception times using R_rx\n",
    "            self.lever_arm_pos_rx[:,[ping]]=self.R_rx[ping]@vessel.lever_arm_pos\n",
    "            self.lever_arm_rec_rx[:,[ping]]=self.R_rx[ping]@vessel.lever_arm_rec\n",
    "            \n",
    "            # Calculate the lever arm to the virtual transucer located at the mean position\n",
    "            # of the transmitter and receiver\n",
    "            self.la_trans_rec_txrx[:,[ping]] = (self.lever_arm_trans_tx[:,[ping]]+self.lever_arm_rec_rx[:,[ping]])/2\n",
    "\n",
    "            # Calculate depth as height relative to the ships transducer\n",
    "            # Note that this requires both the waterline and the lever_arm to get the right starting point \n",
    "            # in the water column - not heave - as we assume that the profile moves up and down with the surface.\n",
    "            self.depth[ping] = sound_speed_profile.depth(self.la_trans_rec_txrx[2,[ping]]-vessel.wl, twtt.twtts[ping])\n",
    "            \n",
    "            # Now determine the rp and transducer position at the transmits\n",
    "            # Be careful about axis alignment!\n",
    "            self.pos_rp_tx[0,[ping]]=self.pos_proj_ant_tx[0,[ping]]-self.lever_arm_pos_tx[1,[ping]]\n",
    "            self.pos_rp_tx[1,[ping]]=self.pos_proj_ant_tx[1,[ping]]-self.lever_arm_pos_tx[0,[ping]]\n",
    "            self.pos_rp_tx[2,[ping]]=self.pos_proj_ant_tx[2,[ping]]-self.lever_arm_pos_tx[2,[ping]]\n",
    "            self.pos_trans_tx[:,[ping]]=self.pos_rp_tx[:,[ping]]+self.lever_arm_trans_tx[:,[ping]]\n",
    "\n",
    "            # Now determine the rp and transducer position at reception\n",
    "            self.pos_rp_rx[0,[ping]]=self.pos_proj_ant_rx[0,[ping]]-self.lever_arm_pos_rx[1,[ping]]\n",
    "            self.pos_rp_rx[1,[ping]]=self.pos_proj_ant_rx[1,[ping]]-self.lever_arm_pos_rx[0,[ping]]\n",
    "            self.pos_rp_rx[2,[ping]]=self.pos_proj_ant_rx[2,[ping]]-self.lever_arm_pos_rx[2,[ping]]\n",
    "            self.pos_rec_rx[:,[ping]]=self.pos_rp_rx[:,[ping]]+self.lever_arm_rec_rx[:,[ping]]\n",
    "\n",
    "            # update the ping count\n",
    "            ping += 1\n",
    "            \n",
    "        print(\"Done integrating sounding data from source\"+twtt.metadata['Source_File'])\n",
    "\n",
    "    def draw(self):\n",
    "        fig=plt.figure(figsize=(12, 6))\n",
    "        ax1 = plt.subplot(3,1,1)\n",
    "        plt.plot(self.twtt.times, self.twtt.twtts*np.mean(self.ssp.obs_ss)/2)\n",
    "        plt.plot(self.twtt.times, self.twtt.twtts *\n",
    "             np.mean(self.ssp.obs_ss)/2+(self.h_tx+self.h_rx)/2+self.la_trans_rec_txrx[2,:])\n",
    "        plt.plot(self.twtt.times, self.depth+(self.h_tx+self.h_rx)/2+self.la_trans_rec_txrx[2,:])\n",
    "\n",
    "        plt.title('Depths [m]')\n",
    "        plt.ylabel('Depths [m] →')\n",
    "        plt.xlabel('Time ('+self.twtt.metadata['time_basis']+') →')\n",
    "        ax1.invert_yaxis()\n",
    "    \n",
    "        ax2 = plt.subplot(3,1,2)\n",
    "        plt.plot(self.twtt.times, (self.twtt.twtts * \\\n",
    "         np.mean(self.ssp.obs_ss)/2+(self.h_tx+self.h_rx)/2+self.la_trans_rec_txrx[2,:])-(self.depth+(self.h_tx+self.h_rx)/2+self.la_trans_rec_txrx[2,:]))\n",
    "    \n",
    "        plt.title('Depths [m]')\n",
    "        plt.ylabel('Depths [m] →')\n",
    "        plt.xlabel('Time ('+self.twtt.metadata['time_basis']+') →')\n",
    "        ax2.invert_yaxis()\n",
    "        \n",
    "        ax3 = plt.subplot(3,1,3)\n",
    "        twtt_times=self.twtt.times[0:100]\n",
    "        twtts=self.twtt.twtts[0:100]\n",
    "        obs_ss=self.ssp.obs_ss[0:100]\n",
    "        h_tx=self.h_tx[0:100]\n",
    "        h_rx=self.h_rx[0:100]\n",
    "        la=self.la_trans_rec_txrx[2,0:100]\n",
    "        depth=self.depth[0:100]\n",
    "        ant_tx_full=self.pos_proj_ant_rx[:,0:100]\n",
    "        rp_tx_full=self.pos_rp_tx[:,0:100]\n",
    "        trans_tx_full=self.pos_trans_tx[:,0:100]\n",
    "        \n",
    "        plt.plot(twtt_times, (twtts * \\\n",
    "                  np.mean(obs_ss)/2+(h_tx+h_rx)/2+la)- \\\n",
    "                   (depth+(h_tx+h_rx)/2+la))\n",
    "    \n",
    "        plt.plot(twtt_times,(h_tx+h_rx)/300+.125)\n",
    "        plt.title('Depths [m]')\n",
    "        plt.ylabel('Depths [m] →')\n",
    "        plt.xlabel('Time ('+self.twtt.metadata['time_basis']+') →')\n",
    "        ax3.invert_yaxis()\n",
    "        \n",
    "        # Space out the plots so that they do not overlap\n",
    "        plt.subplots_adjust(top = 0.99, bottom=0.01, hspace=.5, wspace=0.4)\n",
    "        plt.show()        \n",
    "        \n",
    "        # Plot the navigation\n",
    "        fig=plt.figure(figsize=(12, 6))\n",
    "        ax4 = plt.subplot(2,1,1)\n",
    "        plt.plot(self.pos_proj_ant_rx[0,:],self.pos_proj_ant_rx[1,:],'b.',label='Antenna')\n",
    "        plt.plot(self.pos_rp_tx[0,:],self.pos_rp_tx[1,:],'r.',label='RP')\n",
    "        plt.plot(self.pos_trans_tx[0,:],self.pos_trans_tx[1,:],'k.',label='Transducer')\n",
    "        plt.legend()\n",
    "        plt.axis('equal')\n",
    "        ax5 = plt.subplot(2,1,2)\n",
    "        plt.plot(ant_tx_full[0,0:100],ant_tx_full[1,0:100],'b.',label='Antenna')\n",
    "        plt.plot(rp_tx_full[0,0:100],rp_tx_full[1,0:100],'r.',label='RP')\n",
    "        plt.plot(trans_tx_full[0,0:100],trans_tx_full[1,0:100],'k.',label='Transducer')\n",
    "        plt.axis('equal')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    \n",
    "    def draw_depths(self):\n",
    "        fig=plt.figure(figsize=(12, 6))\n",
    "        plt.plot(self.twtt.times, self.depth+(self.h_tx+self.h_rx)/2+self.la_trans_rec_txrx[2,:])\n",
    "\n",
    "        plt.title('Depths [m]')\n",
    "        plt.ylabel('Depths [m] →')\n",
    "        plt.xlabel('Time ('+self.twtt.metadata['time_basis']+') →')\n",
    "        plt.gca().invert_yaxis()\n",
    "    \n",
    "            \n",
    "    def heave_gnss():\n",
    "        # Determine heave from the rp trajectorty\n",
    "        # Use an 30 second filtering window\n",
    "         return heave\n",
    "        \n",
    "    def qc(self):\n",
    "        # The match of the IMU heave to the positioning z-component is one quality control indicator\n",
    "        \n",
    "        fig=plt.figure(figsize=(12, 6))\n",
    "        ax1 = plt.subplot(3,1,1)\n",
    "#         plt.plot(self.twtt.times, self.pos_ant\n",
    "#         plt.plot(self.twtt.times, self.depth+(self.h_tx+self.h_rx)/2+self.la_trans_rec_txrx)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening Two Way Travel Time (TWTT) data file:/home/jupyter-semmed/ESCI_OE_774_874/Lab_A/Lab_A_TWTT.txt\n",
      "Opening GNSS data file:/home/jupyter-semmed/ESCI_OE_774_874/Lab_A/Lab_A_GNSS.txt\n",
      "Opening motion data file:/home/jupyter-semmed/ESCI_OE_774_874/Lab_A/Lab_A_MRU.txt\n",
      "Opening water level data file:/home/jupyter-semmed/ESCI_OE_774_874/Lab_A/Lab_A_TIDE.txt\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'wl_lines' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-d4bcdeaea332>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Water level data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mwater_levels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWaterLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mwater_levels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_jhc_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/Lab_A_TIDE.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# Sound speed data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-890b1449960e>\u001b[0m in \u001b[0;36mread_jhc_file\u001b[0;34m(self, fullpath)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Source File\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfullpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Opening water level data file:'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfullpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwl_lines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Raise a meaningful error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Unable to locate the input file'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfullpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'wl_lines' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# Create soundings by integrating the various data streams.\n",
    "# We also need a Vessel class to store the geometric data descriptive of the vessel\n",
    "\n",
    "vessel = Vessel()\n",
    "vessel.lever_arm_trans = np.array([16.26, -1.75,   4.15]).reshape((3, 1))\n",
    "vessel.lever_arm_rec = np.array([14.82, -2.01,   4.17]).reshape((3, 1))\n",
    "vessel.lever_arm_pos = np.array([-5.73, -0.12, -30.00]).reshape((3, 1))\n",
    "vessel.lever_arm_mru = np.array([0, 0, 0]).reshape((3, 1))\n",
    "vessel.wl = -2.59\n",
    "\n",
    "# Get the data path\n",
    "abs_path = os.path.abspath(os.path.curdir)\n",
    "\n",
    "# TWTTs\n",
    "twtt = EchoSounderData()\n",
    "twtt.read_jhc_file(abs_path+'/Lab_A_TWTT.txt')\n",
    "\n",
    "# positions\n",
    "pos = Position()\n",
    "pos.read_jhc_file(abs_path+'/Lab_A_GNSS.txt')\n",
    "# make sure that there is Cartesian representation of the positions, z-coordinates should be orthometric\n",
    "pos.carto_project('utm','ortho')\n",
    "\n",
    "# Motion data\n",
    "motions = Motion()\n",
    "motions.read_jhc_file(abs_path+'/Lab_A_MRU.txt')\n",
    "\n",
    "# Water level data\n",
    "water_levels = WaterLevel()\n",
    "water_levels.read_jhc_file(abs_path+'/Lab_A_TIDE.txt')\n",
    "\n",
    "# Sound speed data\n",
    "sound_speed_profile = SSP()\n",
    "sound_speed_profile.read_jhc_file(abs_path+'/Lab_A_SVP.txt')\n",
    "\n",
    "# Integrate all the data\n",
    "integration=Integration(twtt,pos,motions,sound_speed_profile, water_levels, vessel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "water_levels.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the `draw` method of the object `pos` to draw the general location of the survey on the earth and a large scale plot of the navigation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Show the associated motion data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motions.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Finally, show the two way travel data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twtt.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ping=0\n",
    "# integration.la_trans_rec_txrx[:,[ping]] = (integration.lever_arm_trans_tx[:,[ping]]+integration.lever_arm_rec_rx[:,[ping]])/2\n",
    "# integration.draw()\n",
    "(integration.lever_arm_trans_tx[:,[ping]]+integration.lever_arm_rec_rx[:,[ping]])/2\n",
    "integration.draw()\n",
    "integration.draw_depths()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=plt.subplot()\n",
    "ax.xaxis.set_major_formatter(ticker.FormatStrFormatter(\"%d\"))\n",
    "ax.yaxis.set_major_formatter(ticker.FormatStrFormatter(\"%d\"))\n",
    "plt.title('Positions Moving East (' + pos.get_carto()+')')\n",
    "plt.plot(integration.pos_proj_ant_rx[0,0:100],integration.pos_proj_ant_rx[1,0:100],'b.',label='Antenna')\n",
    "plt.plot(integration.pos_rp_rx[0,0:100],integration.pos_rp_rx[1,0:100],'r.',label='RP')\n",
    "plt.plot(integration.pos_rec_rx[0,0:100],integration.pos_rec_rx[1,0:100],'k.',label='Tx Transducer')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "pos.proj_pos[:,[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lever_arm_pos_tx=np.zeros([3,100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def carto_print():\n",
    "    pos.metadata['proj_str']\n",
    "    s_carto=pos.metadata['proj_str']\n",
    "    prj=''\n",
    "    for ss in s_carto.split():\n",
    "        ss=ss.split('=')\n",
    "        if s[0] == '+proj':\n",
    "            prj=s[1]\n",
    "        elif s[0] == '+zone':\n",
    "            zone=s[1]\n",
    "        elif s[0] == '+north':\n",
    "             hemi = 'N'\n",
    "        elif s[0] == '+south':\n",
    "             hemi = 'S'\n",
    "        elif s[0] == '+ellps':\n",
    "             ellipse = s[1]\n",
    "        elif s[0] == '+datum':\n",
    "             datum = s[1]\n",
    "           \n",
    "    if prj=='utm':\n",
    "        print( 'UTM zone: ' + zone + hemi + ' on ' + ellipse)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos.metadata['proj_str']\n",
    "s_carto=pos.metadata['proj_str']\n",
    "prj=''\n",
    "for ss in s_carto.split():\n",
    "    ss=ss.split('=')\n",
    "    if ss[0] == '+proj':\n",
    "        prj=ss[1]\n",
    "    elif ss[0] == '+zone':\n",
    "        zone=ss[1]\n",
    "    elif ss[0] == '+north':\n",
    "        hemi = 'N'\n",
    "    elif ss[0] == '+south':\n",
    "        hemi = 'S'\n",
    "    elif ss[0] == '+ellps':\n",
    "        ellipse = ss[1]\n",
    "    elif ss[0] == '+datum':\n",
    "        datum = ss[1]\n",
    "           \n",
    "if prj=='utm':\n",
    "    print( 'UTM zone: ' + zone + hemi + ' on ' + ellipse)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos.metadata['proj_str']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
